{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisher + callhome sp/es - en configuration\n",
      "--------------------------------------------------\n",
      "loading info_dict from=./both_fbank_out/info.dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3977/3977 [00:00<00:00, 497309.25it/s]\n",
      "100%|██████████| 3959/3959 [00:00<00:00, 507681.59it/s]\n",
      "100%|██████████| 3641/3641 [00:00<00:00, 468205.56it/s]\n",
      " 32%|███▏      | 44388/138708 [00:00<00:00, 443875.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "creating buckets for: fisher_dev\n",
      "creating buckets for key: es_c\n",
      "creating buckets for: fisher_dev2\n",
      "creating buckets for key: es_c\n",
      "creating buckets for: fisher_test\n",
      "creating buckets for key: es_c\n",
      "creating buckets for: fisher_train\n",
      "creating buckets for key: es_c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138708/138708 [00:00<00:00, 434826.51it/s]\n",
      "100%|██████████| 3801/3801 [00:00<00:00, 402599.80it/s]\n",
      "100%|██████████| 1824/1824 [00:00<00:00, 434880.09it/s]\n",
      "100%|██████████| 14284/14284 [00:00<00:00, 450529.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating buckets for: callhome_devtest\n",
      "creating buckets for key: es_c\n",
      "creating buckets for: callhome_evltest\n",
      "creating buckets for key: es_c\n",
      "creating buckets for: callhome_train\n",
      "creating buckets for key: es_c\n",
      "--------------------------------------------------\n",
      "saving info dict in: ./both_fbank_out/buckets_es_c.dict\n",
      "all done ...\n",
      "--------------------------------------------------\n",
      "showing buckets for category: fisher_dev\n",
      "number of buckets=15, width of each bucket=15\n",
      "index | width | num   \n",
      "    0 |     0 |   1406\n",
      "    1 |    15 |    557\n",
      "    2 |    30 |    378\n",
      "    3 |    45 |    347\n",
      "    4 |    60 |    254\n",
      "    5 |    75 |    198\n",
      "    6 |    90 |    177\n",
      "    7 |   105 |    166\n",
      "    8 |   120 |    149\n",
      "    9 |   135 |    136\n",
      "   10 |   150 |     90\n",
      "   11 |   165 |     57\n",
      "   12 |   180 |     27\n",
      "   13 |   195 |     16\n",
      "   14 |   210 |     19\n",
      "--------------------------------------------------\n",
      "showing buckets for category: fisher_dev2\n",
      "number of buckets=15, width of each bucket=15\n",
      "index | width | num   \n",
      "    0 |     0 |   1333\n",
      "    1 |    15 |    569\n",
      "    2 |    30 |    497\n",
      "    3 |    45 |    349\n",
      "    4 |    60 |    251\n",
      "    5 |    75 |    196\n",
      "    6 |    90 |    169\n",
      "    7 |   105 |    130\n",
      "    8 |   120 |    144\n",
      "    9 |   135 |    119\n",
      "   10 |   150 |     73\n",
      "   11 |   165 |     56\n",
      "   12 |   180 |     29\n",
      "   13 |   195 |     19\n",
      "   14 |   210 |     25\n",
      "--------------------------------------------------\n",
      "showing buckets for category: fisher_test\n",
      "number of buckets=15, width of each bucket=15\n",
      "index | width | num   \n",
      "    0 |     0 |   1242\n",
      "    1 |    15 |    464\n",
      "    2 |    30 |    376\n",
      "    3 |    45 |    293\n",
      "    4 |    60 |    229\n",
      "    5 |    75 |    176\n",
      "    6 |    90 |    128\n",
      "    7 |   105 |    111\n",
      "    8 |   120 |    192\n",
      "    9 |   135 |    151\n",
      "   10 |   150 |     99\n",
      "   11 |   165 |     85\n",
      "   12 |   180 |     57\n",
      "   13 |   195 |     16\n",
      "   14 |   210 |     22\n",
      "--------------------------------------------------\n",
      "showing buckets for category: fisher_train\n",
      "number of buckets=15, width of each bucket=15\n",
      "index | width | num   \n",
      "    0 |     0 |  45466\n",
      "    1 |    15 |  18859\n",
      "    2 |    30 |  14925\n",
      "    3 |    45 |  11735\n",
      "    4 |    60 |   9121\n",
      "    5 |    75 |   7292\n",
      "    6 |    90 |   5786\n",
      "    7 |   105 |   5388\n",
      "    8 |   120 |   5901\n",
      "    9 |   135 |   5350\n",
      "   10 |   150 |   3886\n",
      "   11 |   165 |   2372\n",
      "   12 |   180 |   1339\n",
      "   13 |   195 |    646\n",
      "   14 |   210 |    642\n",
      "--------------------------------------------------\n",
      "showing buckets for category: callhome_devtest\n",
      "number of buckets=15, width of each bucket=15\n",
      "index | width | num   \n",
      "    0 |     0 |   1138\n",
      "    1 |    15 |    671\n",
      "    2 |    30 |    537\n",
      "    3 |    45 |    413\n",
      "    4 |    60 |    290\n",
      "    5 |    75 |    210\n",
      "    6 |    90 |    154\n",
      "    7 |   105 |     85\n",
      "    8 |   120 |     80\n",
      "    9 |   135 |     70\n",
      "   10 |   150 |     42\n",
      "   11 |   165 |     28\n",
      "   12 |   180 |     26\n",
      "   13 |   195 |     23\n",
      "   14 |   210 |     34\n",
      "--------------------------------------------------\n",
      "showing buckets for category: callhome_evltest\n",
      "number of buckets=15, width of each bucket=15\n",
      "index | width | num   \n",
      "    0 |     0 |    495\n",
      "    1 |    15 |    329\n",
      "    2 |    30 |    264\n",
      "    3 |    45 |    185\n",
      "    4 |    60 |    141\n",
      "    5 |    75 |    106\n",
      "    6 |    90 |     62\n",
      "    7 |   105 |     57\n",
      "    8 |   120 |     48\n",
      "    9 |   135 |     33\n",
      "   10 |   150 |     28\n",
      "   11 |   165 |     18\n",
      "   12 |   180 |     18\n",
      "   13 |   195 |      9\n",
      "   14 |   210 |     31\n",
      "--------------------------------------------------\n",
      "showing buckets for category: callhome_train\n",
      "number of buckets=15, width of each bucket=15\n",
      "index | width | num   \n",
      "    0 |     0 |   4332\n",
      "    1 |    15 |   2501\n",
      "    2 |    30 |   2011\n",
      "    3 |    45 |   1437\n",
      "    4 |    60 |   1049\n",
      "    5 |    75 |    750\n",
      "    6 |    90 |    526\n",
      "    7 |   105 |    405\n",
      "    8 |   120 |    334\n",
      "    9 |   135 |    253\n",
      "   10 |   150 |    217\n",
      "   11 |   165 |    139\n",
      "   12 |   180 |    111\n",
      "   13 |   195 |     76\n",
      "   14 |   210 |    143\n",
      "cnn details:\n",
      "{'in_channels': None, 'out_channels': 32, 'ksize': (3, 3), 'stride': (2, 2), 'pad': (1, 1)}\n",
      "{'in_channels': None, 'out_channels': 32, 'ksize': (5, 3), 'stride': (3, 2), 'pad': (2, 1)}\n",
      "--------------------------------------------------\n",
      "loading dict: ./both_fbank_out/map.dict\n",
      "loading dict: ./both_fbank_out/train_vocab.dict\n",
      "--------------------------------------------------\n",
      "loading dict: ./both_fbank_out/buckets_es_c.dict\n",
      "--------------------------------------------------\n",
      "utterances in fisher_dev = 3979\n",
      "utterances in fisher_dev2 = 3961\n",
      "utterances in fisher_test = 3641\n",
      "utterances in fisher_train = 138819\n",
      "utterances in callhome_devtest = 3966\n",
      "utterances in callhome_evltest = 1829\n",
      "utterances in callhome_train = 15080\n",
      "vocab size for es_c = 55\n",
      "vocab size for en_c = 62\n",
      "model file name: nov18/seq2seq_sen-138819_hwy0-dec3_emb-100-h-300__fsh_25__es_c_en_c_gru_drpt-0.3_noise-0_l2-0.001000_32_32_2_3_2DCNN_BN_LN_enc-3.model\n",
      "log file name: nov18/train_sen-138819_hwy0-dec3_emb-100-h-300__fsh_25__es_c_en_c_gru_drpt-0.3_noise-0_l2-0.001000_32_32_2_3_2DCNN_BN_LN_enc-3.log\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport basics\n",
    "%aimport nn_config\n",
    "%aimport enc_dec\n",
    "\n",
    "from basics import *\n",
    "from nn_config import *\n",
    "from enc_dec import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_out_dim = rnn_in_units =  800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer3/lib/python3.6/site-packages/chainer/utils/experimental.py:104: FutureWarning: chainer.links.normalization.layer_normalization.py is experimental. The interface can change in the future.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ADAM optimizer\n"
     ]
    }
   ],
   "source": [
    "from nmt_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "model not found\n"
     ]
    }
   ],
   "source": [
    "last_epoch = check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_dict = map_dict['fisher_dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_ref0 = {}\n",
    "for utt in m_dict:\n",
    "    line_str = \" \".join([w.decode() for w in m_dict[utt]['en_w'][0]])\n",
    "    line_ref0[utt] = line_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_str = 'mmh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20051026_211309_346_fsp-A-80'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20051009_182032_217_fsp-B-1',\n",
       " '20051009_182032_217_fsp-A-1',\n",
       " '20051009_182032_217_fsp-B-2',\n",
       " '20051009_182032_217_fsp-A-2',\n",
       " '20051009_182032_217_fsp-B-3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(line_ref0.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20051009_182032_217_fsp-B-36 mmh\n",
      "20051009_182032_217_fsp-A-45 mmh\n",
      "20051009_182032_217_fsp-A-47 mmh\n",
      "20051009_182032_217_fsp-A-112 mmh\n",
      "20051009_182032_217_fsp-A-118 mmh\n",
      "20051016_180547_265_fsp-B-27 mmm mmh yes shudong yes\n",
      "20051016_180547_265_fsp-B-44 mmh\n",
      "20051016_180547_265_fsp-A-47 mmh\n",
      "20051016_210626_267_fsp-A-18 mmh\n",
      "20051016_210626_267_fsp-A-19 mmh\n",
      "20051016_210626_267_fsp-A-34 mmh\n",
      "20051018_210744_280_fsp-B-14 mmh\n",
      "20051018_210744_280_fsp-B-17 mmh\n",
      "20051019_190221_288_fsp-A-63 mmh\n",
      "20051019_190221_288_fsp-A-65 mmh\n",
      "20051019_190221_288_fsp-A-66 mmh\n",
      "20051024_181110_329_fsp-A-70 ok mmh pe\n",
      "20051024_181110_329_fsp-A-71 mmh mmh mmh\n",
      "20051024_181110_329_fsp-A-72 mmh mmh\n",
      "20051024_181110_329_fsp-A-78 mmh\n",
      "20051024_181110_329_fsp-A-79 mmh mmh\n"
     ]
    }
   ],
   "source": [
    "for utt, line_str in line_ref0.items():\n",
    "    if search_str in line_str:\n",
    "        print(utt, line_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = L.Linear(5,5, nobias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a dimensions: batch_size, sequence length, hidden units\n",
    "a = Variable(np.random.randn(9,7,5).astype(np.float32))\n",
    "b = Variable(np.random.randn(1,5).astype(np.float32))\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = t(b)\n",
    "# F.matmul(a,x, transb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F.softmax(F.matmul(a,t(b),transb=True),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.rollaxis(a,2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_full_length_batch(m_dict, x_key, y_key,\n",
    "              utt_list, vocab_dict,\n",
    "              max_enc, max_dec, cat_speech_path=''):\n",
    "\n",
    "    batch_data = {'X':[], 'y':[]}\n",
    "    for u in utt_list:\n",
    "        # for speech data\n",
    "        x_data_found = False\n",
    "        if x_key == 'sp':\n",
    "            utt_sp_path = os.path.join(cat_speech_path,\n",
    "                                      \"{0:s}.npy\".format(u))\n",
    "            if not os.path.exists(utt_sp_path):\n",
    "                utt_sp_path = os.path.join(cat_speech_path,\n",
    "                                           u.split('_',1)[0],\n",
    "                                           \"{0:s}.npy\".format(u))\n",
    "            if os.path.exists(utt_sp_path):\n",
    "                x_data_found = True\n",
    "                x_data = xp.load(utt_sp_path)\n",
    "                print(x_data.shape)\n",
    "                batch_data['X'].append(x_data)\n",
    "            else:\n",
    "                print(\"ERROR!! file not found: {0:s}\".format(utt_sp_path))\n",
    "        else:\n",
    "            u_x_ids = [vocab_dict[x_key]['w2i'].get(w, UNK_ID) for w in m_dict[u][x_key]]\n",
    "            u_x_ids = xp.asarray(u_x_ids, dtype=xp.int32)\n",
    "            x_data_found = True\n",
    "            batch_data['X'].append(u_x_ids)\n",
    "        #  add english labels\n",
    "\n",
    "        if x_data_found:\n",
    "            if type(m_dict[u][y_key]) == list:\n",
    "                en_ids = [vocab_dict[y_key]['w2i'].get(w, UNK_ID) for w in m_dict[u][y_key]]\n",
    "            else:\n",
    "                # dev and test data have multiple translations\n",
    "                # choose the first one for computing perplexity\n",
    "                en_ids = [vocab_dict[y_key]['w2i'].get(w, UNK_ID) for w in m_dict[u][y_key][0]]\n",
    "            u_y_ids = [GO_ID] + en_ids + [EOS_ID]\n",
    "            if x_data_found == True:\n",
    "                batch_data['y'].append(xp.asarray(u_y_ids, dtype=xp.int32))\n",
    "    # end for all utterances in batch\n",
    "    if len(batch_data['X']) > 0 and len(batch_data['y']) > 0:\n",
    "        batch_data['X'] = F.pad_sequence(batch_data['X'], padding=PAD_ID)\n",
    "        batch_data['y'] = F.pad_sequence(batch_data['y'], padding=PAD_ID)\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = 'fisher_dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_dict=bucket_dict[key]\n",
    "m_dict = map_dict[key]\n",
    "vocab_dict=vocab_dict\n",
    "batch_size=200\n",
    "x_key=enc_key\n",
    "y_key=dec_key\n",
    "train=False\n",
    "cat_speech_path=os.path.join(out_path, key)\n",
    "\n",
    "b = num_b-1\n",
    "# b = 9\n",
    "bucket = b_dict['buckets'][b]\n",
    "b_len = len(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 19)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_b, b_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utt_list = bucket[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20051009_210519_219_fsp-A-67',\n",
       " '20051009_210519_219_fsp-A-74',\n",
       " '20051010_212418_225_fsp-A-36',\n",
       " '20051016_180547_265_fsp-B-66',\n",
       " '20051017_180712_270_fsp-B-72',\n",
       " '20051017_220530_275_fsp-A-30',\n",
       " '20051018_210220_279_fsp-A-35',\n",
       " '20051018_210220_279_fsp-A-55',\n",
       " '20051018_210220_279_fsp-A-58',\n",
       " '20051018_210744_280_fsp-B-41',\n",
       " '20051019_230329_292_fsp-B-33',\n",
       " '20051019_230329_292_fsp-B-63',\n",
       " '20051022_180817_311_fsp-A-30',\n",
       " '20051024_181110_329_fsp-B-52',\n",
       " '20051024_181110_329_fsp-A-63',\n",
       " '20051024_181110_329_fsp-B-81',\n",
       " '20051026_180724_341_fsp-B-10',\n",
       " '20051026_211309_346_fsp-B-66',\n",
       " '20051026_211309_346_fsp-B-76']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4957687ad6cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-4957687ad6cb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "\"\".join([w.decode() for w in m_dict[utt_list[0]]['en_c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-18baa32f1b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en_w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-18baa32f1b46>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en_w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "\" \".join([w.decode() for w in m_dict[utt_list[0]]['en_w']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 700)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.L0_dec.W.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b6c999f914d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0men_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0men_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w2i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNK_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-b6c999f914d5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0men_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0men_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w2i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNK_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "en_chars = [w.decode() for w in m_dict[utt_list[0]][y_key]]\n",
    "en_ids = [str(vocab_dict[y_key]['w2i'].get(w, UNK_ID)) for w in m_dict[utt_list[0]][y_key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14',\n",
       " '21',\n",
       " '22',\n",
       " '5',\n",
       " '11',\n",
       " '14',\n",
       " '21',\n",
       " '22',\n",
       " '5',\n",
       " '11',\n",
       " '13',\n",
       " '17',\n",
       " '24',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '20',\n",
       " '27',\n",
       " '5',\n",
       " '11',\n",
       " '9',\n",
       " '11',\n",
       " '24',\n",
       " '7',\n",
       " '17',\n",
       " '26',\n",
       " '10',\n",
       " '11',\n",
       " '16',\n",
       " '17',\n",
       " '7',\n",
       " '8',\n",
       " '11',\n",
       " '9',\n",
       " '17',\n",
       " '11',\n",
       " '7',\n",
       " '10',\n",
       " '4',\n",
       " '5',\n",
       " '22',\n",
       " '11',\n",
       " '23',\n",
       " '7',\n",
       " '21',\n",
       " '17',\n",
       " '10',\n",
       " '22',\n",
       " '9',\n",
       " '5',\n",
       " '14',\n",
       " '11',\n",
       " '27',\n",
       " '21',\n",
       " '10',\n",
       " '11',\n",
       " '4',\n",
       " '5',\n",
       " '22',\n",
       " '5',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '20',\n",
       " '27',\n",
       " '5',\n",
       " '11',\n",
       " '14',\n",
       " '7',\n",
       " '12',\n",
       " '5',\n",
       " '10',\n",
       " '9',\n",
       " '12',\n",
       " '5',\n",
       " '14',\n",
       " '11',\n",
       " '10',\n",
       " '4',\n",
       " '5',\n",
       " '11',\n",
       " '8',\n",
       " '7',\n",
       " '12',\n",
       " '5',\n",
       " '17',\n",
       " '11',\n",
       " '13',\n",
       " '22',\n",
       " '5',\n",
       " '11',\n",
       " '22',\n",
       " '5',\n",
       " '13',\n",
       " '6',\n",
       " '6',\n",
       " '20',\n",
       " '11',\n",
       " '6',\n",
       " '7',\n",
       " '17',\n",
       " '5',\n",
       " '6',\n",
       " '20',\n",
       " '11',\n",
       " '5',\n",
       " '12',\n",
       " '11',\n",
       " '23',\n",
       " '13',\n",
       " '22',\n",
       " '9',\n",
       " '17',\n",
       " '18',\n",
       " '11',\n",
       " '25',\n",
       " '7',\n",
       " '22',\n",
       " '11',\n",
       " '10',\n",
       " '4',\n",
       " '5',\n",
       " '11',\n",
       " '16',\n",
       " '9',\n",
       " '24',\n",
       " '14',\n",
       " '11',\n",
       " '6',\n",
       " '9',\n",
       " '16',\n",
       " '5',\n",
       " '11',\n",
       " '5',\n",
       " '19',\n",
       " '5',\n",
       " '17',\n",
       " '11',\n",
       " '10',\n",
       " '4',\n",
       " '5',\n",
       " '11',\n",
       " '23',\n",
       " '7',\n",
       " '12',\n",
       " '12',\n",
       " '21',\n",
       " '17',\n",
       " '9',\n",
       " '10',\n",
       " '20',\n",
       " '11',\n",
       " '7',\n",
       " '22',\n",
       " '11',\n",
       " '10',\n",
       " '4',\n",
       " '5',\n",
       " '11',\n",
       " '22',\n",
       " '5',\n",
       " '6',\n",
       " '13',\n",
       " '10',\n",
       " '9',\n",
       " '19',\n",
       " '5',\n",
       " '14',\n",
       " '11',\n",
       " '14',\n",
       " '7',\n",
       " '12',\n",
       " '5',\n",
       " '10',\n",
       " '9',\n",
       " '12',\n",
       " '5',\n",
       " '14',\n",
       " '11',\n",
       " '10',\n",
       " '4',\n",
       " '5',\n",
       " '22',\n",
       " '5',\n",
       " '11',\n",
       " '9',\n",
       " '14',\n",
       " '17',\n",
       " '26',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '21',\n",
       " '23',\n",
       " '4',\n",
       " '11',\n",
       " '14',\n",
       " '21',\n",
       " '15',\n",
       " '15',\n",
       " '7',\n",
       " '22',\n",
       " '10',\n",
       " '11',\n",
       " '25',\n",
       " '22',\n",
       " '7',\n",
       " '12',\n",
       " '11',\n",
       " '7',\n",
       " '10',\n",
       " '4',\n",
       " '5',\n",
       " '22',\n",
       " '11',\n",
       " '15',\n",
       " '5',\n",
       " '7',\n",
       " '15',\n",
       " '6',\n",
       " '5']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sure sure and maybe i don't know in other countries but here maybe sometimes the women are really lonely em caring for the kids like even the community or the relatives sometimes there isn't much support from other people\n",
      "['14', '21', '22', '5', '11', '14', '21', '22', '5', '11', '13', '17', '24', '11', '12', '13', '20', '27', '5', '11', '9', '11', '24', '7', '17', '26', '10', '11', '16', '17', '7', '8', '11', '9', '17', '11', '7', '10', '4', '5', '22', '11', '23', '7', '21', '17', '10', '22', '9', '5', '14', '11', '27', '21', '10', '11', '4', '5', '22', '5', '11', '12', '13', '20', '27', '5', '11', '14', '7', '12', '5', '10', '9', '12', '5', '14', '11', '10', '4', '5', '11', '8', '7', '12', '5', '17', '11', '13', '22', '5', '11', '22', '5', '13', '6', '6', '20', '11', '6', '7', '17', '5', '6', '20', '11', '5', '12', '11', '23', '13', '22', '9', '17', '18', '11', '25', '7', '22', '11', '10', '4', '5', '11', '16', '9', '24', '14', '11', '6', '9', '16', '5', '11', '5', '19', '5', '17', '11', '10', '4', '5', '11', '23', '7', '12', '12', '21', '17', '9', '10', '20', '11', '7', '22', '11', '10', '4', '5', '11', '22', '5', '6', '13', '10', '9', '19', '5', '14', '11', '14', '7', '12', '5', '10', '9', '12', '5', '14', '11', '10', '4', '5', '22', '5', '11', '9', '14', '17', '26', '10', '11', '12', '21', '23', '4', '11', '14', '21', '15', '15', '7', '22', '10', '11', '25', '22', '7', '12', '11', '7', '10', '4', '5', '22', '11', '15', '5', '7', '15', '6', '5']\n",
      "221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\".join(en_chars))\n",
    "print(en_ids), print(len(en_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer = optimizers.Adam()\n",
    "# optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket size=19\n",
      "0 (19, 225) (19, 250)\n",
      "variable(768.8587646484375)\n"
     ]
    }
   ],
   "source": [
    "print(\"bucket size={0:d}\".format(b_len))\n",
    "\n",
    "for i in range(0,batch_size, batch_size):\n",
    "    utt_list = bucket[i:i+batch_size]\n",
    "    batch_data = get_batch(m_dict, x_key, y_key, utt_list, vocab_dict, ((b+1) * width_b), (80), \n",
    "                           cat_speech_path=cat_speech_path)\n",
    "    \n",
    "    print(i, batch_data['X'].shape, batch_data['y'].shape)\n",
    "    \n",
    "    p, loss = model.forward(batch_data['X'], batch_data['y'])\n",
    "    \n",
    "    model.cleargrads()\n",
    "    \n",
    "    loss.backward()\n",
    "    # loss_1.backward()\n",
    "\n",
    "    # model.addgrads(model_1)\n",
    "    optimizer.update()\n",
    "    \n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': variable([[15, 11, 25, ...,  0,  0,  0],\n",
       "           [23, 12,  6, ..., 25,  5, 12],\n",
       "           [10,  6,  5, ...,  0,  0,  0],\n",
       "           ..., \n",
       "           [23,  9, 12, ...,  0,  0,  0],\n",
       "           [14, 11, 12, ..., 20, 18, 29],\n",
       "           [25,  9, 26, ..., 26,  0,  0]]),\n",
       " 'y': variable([[ 1,  9, 17, ...,  0,  0,  0],\n",
       "           [ 1, 13, 17, ...,  0,  0,  0],\n",
       "           [ 1, 10,  4, ...,  0,  0,  0],\n",
       "           ..., \n",
       "           [ 1,  9, 11, ...,  0,  0,  0],\n",
       "           [ 1, 20,  7, ...,  0,  0,  0],\n",
       "           [ 1,  5, 19, ...,  0,  0,  0]])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/3977 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "EPOCH = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b=13,l=0.00,avg=0.00: 100%|█████████████████| 3977/3977 [01:38<00:00, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** dev mean loss=0.0000\n",
      "-\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*80)\n",
    "print(\"EPOCH = {0:d}\".format(last_epoch+1))\n",
    "fsh_pred_sents, fsh_utts, loss = feed_model(map_dict[key],\n",
    "                  b_dict=bucket_dict[key],\n",
    "                  vocab_dict=vocab_dict,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  x_key=enc_key,\n",
    "                  y_key=dec_key,\n",
    "                  train=train,\n",
    "                  cat_speech_path=cat_speech_path, use_y=False, mini=False)\n",
    "\n",
    "print(\"{0:s} {1:s} mean loss={2:.4f}\".format(\"*\" * 10,\n",
    "                                    \"train\" if train else \"dev\",\n",
    "                                    loss))\n",
    "print(\"-\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsh_pred_sents[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L0_dec.W.W.shape, model.L0_enc.W.W.shape, model.L0_rev_enc.W.W.shape, model.embed_dec.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "256+256+256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L2_dec.W.W[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L2_dec.W.W.data[0,0] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add_weight_noise(0.,0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L2_dec.W.W[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L2_dec.W.update_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L2_dec.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L2_dec.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "20000 * 64 / 138708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.random.normal(0, .125, (5,5), dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.rnn_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L0_dec.W, model.L0_dec.W_r, model.L0_dec.W_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L0_dec.U, model.L0_dec.U_r, model.L0_dec.U_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L0_dec.U.W.shape, model.L0_dec.U.b.shape, model.L0_dec.U_r.W.shape, model.L0_dec.U_r.b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.embed_dec.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.125 # mean and standard deviation\n",
    "\n",
    "for rnn_layer in model.rnn_enc + model.rnn_dec:\n",
    "    print(rnn_layer)\n",
    "    layer_shape = model[rnn_layer][\"W\"].W.shape\n",
    "    print(layer_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce_dim = CNN_IN_DIM\n",
    "cnn_out_dim = 0\n",
    "for i, l in enumerate(cnn_filters):\n",
    "    cnn_out_dim += l[\"out_channels\"]\n",
    "    print(reduce_dim, l[\"stride\"][1])\n",
    "    reduce_dim = math.ceil(reduce_dim / l[\"stride\"][1])\n",
    "    print(reduce_dim)\n",
    "    print(l[\"out_channels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CNN_IN_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_filters[-1][\"out_channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = batch_data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.expand_dims(x,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cleargrads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if lstm1_or_gru0:\n",
    "    print(model.L1_dec.lateral.W.grad)\n",
    "else:\n",
    "    print(model.L1_dec.W.W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.attn_Wa.W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.out.W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if lstm1_or_gru0:\n",
    "    print(model.L0_enc.lateral.W.grad)\n",
    "else:\n",
    "    print(model.L0_enc.W.W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_weights_grads(layer):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20, 10))\n",
    "    plt.axis('off')\n",
    "    weights = layer.data\n",
    "    grads = layer.grad\n",
    "    if gpuid >= 0:\n",
    "        weights = cuda.cupy.asnumpy(weights[:,:])\n",
    "        grads = cuda.cupy.asnumpy(grads[:,:])\n",
    "    # plt.imshow(weights, interpolation='none')\n",
    "    ax1 = sns.heatmap(weights, cmap=\"RdBu_r\", ax=ax1, xticklabels=False, yticklabels=False)\n",
    "    ax2 = sns.heatmap(grads, cmap=\"RdBu_r\", ax=ax2, xticklabels=False, yticklabels=False)\n",
    "    print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model_weights_grads(model.L0_enc.W.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model_weights_grads(model.L1_dec.W.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model_weights_grads(model.out.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.min(model.CNN_0.W.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.nonzero(model.embed_dec.W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_key, y_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_c_utt_lens = []\n",
    "en_c_utt_lens = []\n",
    "total_num = 0\n",
    "for b in b_dict['buckets']:\n",
    "    print(len(b), end=', ')\n",
    "    print(max([len(m_dict[u]['es_w']) for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['es_c']) for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['es_c'])//6 for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['en_w']) for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['en_c']) for u in b]), end=', ')\n",
    "    print(total_num, end=', ')\n",
    "    print(\"\")\n",
    "    total_num += len(b)\n",
    "    es_c_utt_lens.extend([len(m_dict[u]['es_c']) for u in b])\n",
    "    en_c_utt_lens.extend([len(m_dict[u]['en_c']) for u in b])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(es_c_utt_lens, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(en_c_utt_lens, bins=10, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "100 * 10 * 20 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data['X'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_forward_deep_cnn(h):\n",
    "    # check and prepare for 2d convolutions\n",
    "    if CNN_TYPE == DEEP_2D_CNN:\n",
    "        h = F.expand_dims(h, 2)\n",
    "        # h = F.reshape(h, (h.shape[:2] + tuple([-1,SPEECH_DIM // 3])))\n",
    "    h = F.swapaxes(h,1,2)\n",
    "    print(h.shape)\n",
    "\n",
    "    for i, cnn_layer in enumerate(model.cnns):\n",
    "        h = model[cnn_layer](h)\n",
    "        print(h.shape)\n",
    "        # h = F.max_pooling_nd(h, ksize=cnn_max_pool[i],\n",
    "        #                      stride=cnn_max_pool[i],\n",
    "        #                      pad=max_pool_pad)\n",
    "        # batch normalization before non-linearity\n",
    "        if USE_BN:\n",
    "            bn_lname = '{0:s}_bn'.format(cnn_layer)\n",
    "            h = model[bn_lname](h)\n",
    "        h = F.relu(h)\n",
    "        print(h.shape)\n",
    "\n",
    "    # out dimension:\n",
    "    # batch size * num time frames after pooling * cnn out dim\n",
    "    if CNN_TYPE == DEEP_2D_CNN:\n",
    "        h = F.swapaxes(h,1,2)\n",
    "        h = F.reshape(h, h.shape[:2] + tuple([-1]))\n",
    "        h = F.rollaxis(h,1)\n",
    "    else:\n",
    "        h = F.rollaxis(h, 2)\n",
    "    print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = check_forward_deep_cnn(batch_data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = model.forward_deep_cnn(batch_data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(model.cnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.forward_rnn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.forward_enc(batch_data['X'])\n",
    "model.set_decoder_state()\n",
    "y = F.swapaxes(batch_data['y'], 0, 1)\n",
    "# with cmodel.forward_enc(batch_data['X'])\n",
    "# with chainer.using_config('train', True):\n",
    "#     myloss = model.decode_batch(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.enc_states.shape, 1280 /2/3//4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.embed_units*2, model.n_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.L0_dec.W.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.attn_Wa.W.shape, model.context.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = y.shape[1]\n",
    "ht = Variable(xp.zeros((batch_size, 2*model.n_units), dtype=xp.float32))\n",
    "print(ht.shape)\n",
    "for curr_word, next_word in zip(y, y[1:]):\n",
    "    embed_id = model.embed_dec(curr_word)\n",
    "    print(embed_id.shape, curr_word.shape)\n",
    "    rnn_in = F.concat((embed_id, ht), axis=1)\n",
    "    print(rnn_in.shape)\n",
    "    h = model.feed_rnn(rnn_in, model.rnn_dec)\n",
    "    cv, _ = model.compute_context_vector(h)\n",
    "    cv_hdec = F.concat((cv, h), axis=1)\n",
    "    ht = model.context(cv_hdec)\n",
    "    # batch normalization before non-linearity\n",
    "    if USE_BN:\n",
    "        ht = model.context_bn(ht)\n",
    "    ht = F.tanh(ht)\n",
    "\n",
    "    predicted_out = model.out(ht)\n",
    "    print(predicted_out.shape)\n",
    "    print(ht.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht = xp.zeros((y.shape[1],model.n_units), dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.concat((embed_id, ht), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model[model.rnn_enc[-1]].h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_decoder_state(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.enc_states.shape, h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding batch matmul and matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = F.batch_matmul(model.enc_states, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights[0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.enc_states[0].shape, h[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.matmul(model.enc_states[0], h[0])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht = model.attn_Wa(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = F.batch_matmul(model.enc_states, ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = batch_data['X']\n",
    "y = batch_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape, X[0,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = L.Linear(69,10)\n",
    "l1.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1 = l1(X[0,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn1 = L.BatchNormalization(10)\n",
    "bn1.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ln1 = L.LayerNormalization(10)\n",
    "ln1.to_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking BN, LN on network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer normalization\n",
    "xp.mean(h.data,axis=1), xp.var(h.data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.mean(model.L1_dec_ln(h).data,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.mean(h.data,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = batch_data['X']\n",
    "h = F.swapaxes(X,1,2)\n",
    "\n",
    "h = F.relu(model[model.cnns[0]](h))\n",
    "h = F.max_pooling_nd(h, ksize=cnn_max_pool[0],\n",
    "                                 stride=cnn_max_pool[0],\n",
    "                                 pad=max_pool_pad)\n",
    "# h = model.forward_deep_cnn(h)\n",
    "# print(h.shape)\n",
    "# h = F.rollaxis(h, 2)\n",
    "h = F.swapaxes(h,1,2)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "huhu = L.BatchNormalization(256)\n",
    "huhu.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "huhu(h[:,0,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.CNN_0_bn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h.shape, model.CNN_2_bn.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.mean(h.data, axis=(0,1)), xp.var(h.data, axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xp.mean(model.CNN_2_bn(h).data[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.mean(h[0].data,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean and var across all inputs in the batch and the same dimension should be 0, and ~1 respectively\n",
    "\n",
    "The shape should be the number of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2_bn = bn1(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.mean(h1.data,axis=0), xp.var(h1.data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.mean(h2_bn.data,axis=0), xp.var(h2_bn.data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2_ln = ln1(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2_ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean and var across all layer activations within a batch should be 0, and ~1 respectively\n",
    "\n",
    "The shape should be the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp.mean(h2_ln.data,axis=1), xp.var(h2_ln.data,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN across frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = xp.random.randn(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = F.expand_dims(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = F.reshape(a, (-1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.data[1,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = xp.load(\"fbank_out/fisher_train/20050908/20050908_182943_22_fsp-A-1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = F.reshape(a, (1,len(a),-1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = F.swapaxes(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b[0,0,:2,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2d_1 = L.Convolution2D(in_channels=None, \n",
    "                      out_channels=32, \n",
    "                      ksize=(3,3), \n",
    "                      stride=(2,2),pad=3//2)\n",
    "\n",
    "c2d_bn_1 = L.BatchNormalization(32)\n",
    "\n",
    "c2d_2 = L.Convolution2D(in_channels=None, \n",
    "                      out_channels=32, \n",
    "                      ksize=(3,3), \n",
    "                      stride=(2,2),pad=3//2)\n",
    "\n",
    "c2d_bn_2 = L.BatchNormalization(32)\n",
    "\n",
    "c2d_1.to_gpu()\n",
    "c2d_2.to_gpu()\n",
    "c2d_bn_1.to_gpu()\n",
    "c2d_bn_2.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = batch_data['X']\n",
    "y = batch_data['y']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = F.reshape(X, (X.shape[:2] + tuple([-1,SPEECH_DIM // 3])))\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = F.swapaxes(h,1,2)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = c2d_1(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2d_1.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_bn = c2d_bn_1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_bn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = c2d_2(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2d_2.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_bn = c2d_bn_1(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_bn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = F.swapaxes(d, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.shape[:2] + tuple([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = F.reshape(e, e.shape[:2] + tuple([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnd_1 = L.ConvolutionND(ndim=3,\n",
    "                        in_channels=1, \n",
    "                        out_channels=32, \n",
    "                        ksize=(3,3,3), \n",
    "                        stride=2,pad=3//2)\n",
    "\n",
    "cnd_2 = L.ConvolutionND(ndim=3,\n",
    "                        in_channels=1, \n",
    "                        out_channels=32, \n",
    "                        ksize=(3,3,3), \n",
    "                        stride=2,pad=3//2)\n",
    "\n",
    "cnd_1.to_gpu()\n",
    "cnd_2.to_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NStepBiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng_enc = L.NStepGRU(2,SPEECH_DIM, hidden_units, DROPOUT_RATIO)\n",
    "ng_dec = L.NStepGRU(2,hidden_units, hidden_units, DROPOUT_RATIO)\n",
    "ng_enc.to_gpu()\n",
    "ng_dec.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = batch_data['X'][:,:20,:], batch_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_list = list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h,o = ng_enc(hx=None, xs=X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h.shape, len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h[:1].shape,h[-1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Variable(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o = Variable(np.asarray(o))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hd,od = ng_dec(hx=h,xs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sents, loss = feed_model(map_dict[key],\n",
    "                              b_dict=bucket_dict[key],\n",
    "                              vocab_dict=vocab_dict,\n",
    "                              batch_size=64,\n",
    "                              x_key=enc_key,\n",
    "                              y_key=dec_key,\n",
    "                              train=True,\n",
    "                              cat_speech_path=os.path.join(out_path, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(w.decode(),f) for w,f in vocab_dict['es_c']['freq'].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\".join([w.decode() for w in map_dict['fisher_train']['20050908_182943_22_fsp-B-7']['es_c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = cuda.cupy if gpuid >= 0 else np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(vocab_dict[enc_key]['w2i']))\n",
    "print(len(vocab_dict[dec_key]['w2i']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpuid >= 0:\n",
    "    # print(\"here\")\n",
    "    cuda.get_device_from_id(gpuid).use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SpeechEncoderDecoder()\n",
    "\n",
    "if gpuid >= 0:\n",
    "    cuda.get_device(gpuid).use()\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if OPTIMIZER_ADAM1_SGD_0:\n",
    "    print(\"using ADAM optimizer\")\n",
    "    # optimizer = optimizers.Adam(alpha=0.001,\n",
    "    #                             beta1=0.9,\n",
    "    #                             beta2=0.999,\n",
    "    #                             eps=1e-08)\n",
    "    # optimizer = optimizers.AdaGrad()\n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(model)\n",
    "else:\n",
    "    print(\"using SGD optimizer\")\n",
    "    optimizer = optimizers.SGD(lr=0.01)\n",
    "    optimizer.setup(model)\n",
    "\n",
    "if WEIGHT_DECAY:\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(WD_RATIO))\n",
    "\n",
    "# gradient clipping\n",
    "optimizer.add_hook(chainer.optimizer.GradientClipping(threshold=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(map_dict['fisher_train']['20050908_182943_22_fsp-B-7']['en_w']))\n",
    "print(type(map_dict['fisher_dev']['20051009_182032_217_fsp-B-1']['en_w'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_dict['fisher_dev']['20051009_182032_217_fsp-B-1']['en_w'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_model(map_dict['fisher_train'], b_dict=bucket_dict['fisher_train'], \n",
    "           vocab_dict=vocab_dict, batch_size=BATCH_SIZE, \n",
    "           x_key=enc_key, y_key=dec_key, cat_speech_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_dict = pickle.load(open(\"out/train_vocab.dict\", \"rb\"))\n",
    "vocab_dict['es_w']['w2i'][b'solas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_dict['fisher_train']['20050908_182943_22_fsp-B-7']['es_w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(pred_sents), pred_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for b in b_shuffled:\n",
    "    bucket = bucket_dict['fisher_train']['buckets'][b]\n",
    "    b_len = len(bucket)\n",
    "    print(b_len)\n",
    "    for i in range(0,b_len, 32):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise simulation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(map_dict['fisher_train'].keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch = buckets_dict['train'][0]['X_fwd'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_var = np.full(test_batch.shape, 0.01, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = Variable(np.random.normal(0.0, .01, size=test_batch.shape).astype(xp.float32))\n",
    "noise.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_noise = test_batch + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch[0,0,:5], test_batch_noise[0,0,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for consistency in train/dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(set([f.split(\".\")[0] for f in text_data['train'].keys()]), sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(set([f.split(\".\")[0] for f in text_data['dev'].keys()]), sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fids = []\n",
    "for b in buckets_dict[\"train\"]:\n",
    "    train_fids.extend(b['f'])\n",
    "dev_fids = []\n",
    "for b in buckets_dict[\"dev\"]:\n",
    "    dev_fids.extend(b['f'])\n",
    "print(len(train_fids), len(dev_fids))\n",
    "print(set([f.split(\".\")[0] for f in train_fids]), sep=\", \")\n",
    "print(set([f.split(\".\")[0] for f in dev_fids]), sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data['train'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_ids, en_ids = predict(4,2, cat=\"dev\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fil_old = 'small/seq2seq_sen-4000_hwy4-dec2_emb-512-h-512__word_gru_sspkr_drpt-0_noise-0.20_l2-0.001_cnn-num100-range9-199-20-pool900_10.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls $model_fil_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serializers.load_npz(model_fil_old, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pplx_new = compute_pplx(cat=\"dev\", num_sent=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_ids, en_ids = predict(3,2, cat=\"train\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_ids, en_ids = predict(3,2, cat=\"dev\", display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create wavs for dev, dev2 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_dict['fisher_dev']['20051025_212334_337_fsp-B-39']['seg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_segments = list(map_dict['fisher_dev'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(list_of_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'20051025_212334_337_fsp-B-39'.rsplit('-',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_segments[0].rsplit('-',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_of_segments = set([l.rsplit('-',1)[0] for l in list_of_segments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(set_of_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sph2pipe_path = '''/disk/scratch/s1444673/zero/installs/kaldi/egs/fisher_callhome_spanish/s5/../../../tools/sph2pipe_v2.5/sph2pipe'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"callhome_fbank_out/wav.scp\", \"r\") as wavs_f, open(\"callhome_fbank_out/wavs/dev_wavs.scp\", \"w\") as dev_wavs_f:\n",
    "    for line in wavs_f:\n",
    "        for seg in set_of_segments:\n",
    "            if seg in line:\n",
    "#                 print(seg)\n",
    "                out_line =line.split(\" \",1)[1].replace(' |', \" > {0:s}.wav\".format(seg))\n",
    "                dev_wavs_f.write(out_line)\n",
    "#                 subprocess.call([sph2pipe_path, \"-f\", \"wav\", \"-p\", \"-c\", \"1\", ])\n",
    "\n",
    "#         if any(x in line for x in set_of_segments):\n",
    "#             print(line.split(\" \",1)[1])\n",
    "#             dev_wavs_f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_path = \"callhome_fbank_out/wavs/20051009_182032_217_fsp-A.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = scipy.io.wavfile.read(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_dict['fisher_dev']['20051009_182032_217_fsp-B-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(haha[1][:20000], rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = np.load(\"callhome_fbank_out/wavs/20051009_182032_217_fsp-A.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
