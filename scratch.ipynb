{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nmt_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_info = pickle.load(open(\"./mfcc_13dim/info_mboshi.dict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durs = {}\n",
    "lens = {}\n",
    "for c in fisher_info:\n",
    "    print(c)\n",
    "    durs[c] = []\n",
    "    lens[c] = []\n",
    "    for x in tqdm(fisher_info[c], ncols=80):\n",
    "        durs[c].append(fisher_info[c][x]['sp'])\n",
    "        lens[c].append(fisher_info[c][x]['en_w'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in durs:\n",
    "    print(c)\n",
    "    print(\"total hrs = {0:.3f}\".format(sum(durs[c]) / 100. / 3600))\n",
    "    print(\"min = {0:.2f}, max = {1:.2f}, mean = {2:.2f}\".format(np.min(durs[c])/100, \n",
    "                                                                np.max(durs[c])/100, np.mean(durs[c])/100))\n",
    "    print(\"min = {0:.2f}, max = {1:.2f}, mean = {2:.2f}\".format(np.min(lens[c]), \n",
    "                                                                np.max(lens[c]), np.mean(lens[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in durs:\n",
    "    print(c)\n",
    "    print(\"total hrs = {0:.3f}\".format(sum(durs[c]) / 100. / 3600))\n",
    "    print(\"min = {0:.2f}, max = {1:.2f}, mean = {2:.2f}\".format(np.min(durs[c])/100, \n",
    "                                                                np.max(durs[c])/100, np.mean(durs[c])/100))\n",
    "    print(\"min = {0:.2f}, max = {1:.2f}, mean = {2:.2f}\".format(np.min(lens[c]), \n",
    "                                                                np.max(lens[c]), np.mean(lens[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callhome_beam = pickle.load(open(\"./experiments/nmt_asr/callhome_fisher-160_ep75/callhome_devtest_attn_N-5_K-5.dict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callhome_utts = list(callhome_beam.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(callhome_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(callhome_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callhome_map = pickle.load(open(\"./mfcc_13dim/callhome_map.dict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callhome_map_utts = list(callhome_map[\"callhome_devtest\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(callhome_map_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_dict = pickle.load(open(\"./experiments/nmt_asr/callhome_fisher-160_ep75/buckets_sp.dict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callhome_info = pickle.load(open(\"./mfcc_13dim/callhome_info.dict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(callhome_info[\"callhome_devtest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(b) for b in bucket_dict[\"callhome_devtest\"][\"buckets\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callhome_map['callhome_devtest']['sp_0897-B-102']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'sp_0897-B-101' in callhome_utts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = pickle.load(open(\"./mfcc_13dim/info_mboshi.dict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = set(haha[\"mboshi_train\"].keys())\n",
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = set(haha[\"mboshi_test\"].keys())\n",
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(callhome_map_utts), len(set(callhome_map_utts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha = set(callhome_map_utts) - set(callhome_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he = set(callhome_utts) - set(callhome_map_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(he)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids & test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hehe = pickle.load(open(\"./mfcc_13dim/fisher_dev_eval.ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"../subword-nmt/fisher_train.en\"\n",
    "dev_text = \"../subword-nmt/fisher_dev.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text_fname):\n",
    "    words = []\n",
    "    with open(text_fname, \"r\", encoding=\"utf-8\") as in_f:\n",
    "        for line in in_f:\n",
    "            words.extend(line.strip().split())\n",
    "    return Counter(words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counter = get_words(train_text)\n",
    "dev_counter = get_words(dev_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lengths(text_fname):\n",
    "    lengths = []\n",
    "    with open(text_fname, \"r\", encoding=\"utf-8\") as in_f:\n",
    "        for line in in_f:\n",
    "            lengths.append(len(line.strip().split()))\n",
    "    return np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = get_lengths(train_text)\n",
    "dev_lengths = get_lengths(dev_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_lengths), np.min(train_lengths), np.max(train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(dev_lengths), np.min(dev_lengths), np.max(dev_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 75\n",
    "N = len(dev_lengths)\n",
    "N = 3977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_k_most_common(out_fname, K, N):\n",
    "    k_words = \" \".join([i[0] for i in train_counter.most_common(K)])\n",
    "    out_line = \"{0:s}\\n\".format(k_words)\n",
    "    with open(out_fname, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for n in range(N):\n",
    "            out_f.write(out_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_k_most_common(\"./mfcc_13dim/fisher_dummy_top-{0:d}_words.en\".format(K), K=K, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_hyps = pickle.load(open(\"./experiments/nmt_asr/sp-20hrs_swbd1-train100k/fisher_dev_attn_N-5_K-5.dict\",\n",
    "                                \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = pickle.load(open(\"./mfcc_13dim/bpe_map.dict\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_utts = []\n",
    "for u in utt_hyps:\n",
    "    if (len(map_dict[\"fisher_dev\"][u][\"es_w\"]) >= 0 and\n",
    "       len(map_dict[\"fisher_dev\"][u][\"es_w\"]) <= 300):\n",
    "        filt_utts.append(u)\n",
    "\n",
    "filt_utts = sorted(filt_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./mfcc_13dim/fisher_dev_eval.ids\", \"w\") as out_f:\n",
    "    for u in filt_utts:\n",
    "        out_f.write(\"{0:s}\\n\".format(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_test_hyps = pickle.load(open(\"./experiments/nmt_asr/sp-20hrs_swbd1-train-nodev_ep25_enc-attn-dec/fisher_test_attn_N-5_K-5.dict\",\n",
    "                                \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_utts = []\n",
    "for u in utt_test_hyps:\n",
    "    if (len(map_dict[\"fisher_test\"][u][\"es_w\"]) >= 0 and\n",
    "       len(map_dict[\"fisher_test\"][u][\"es_w\"]) <= 300):\n",
    "        filt_utts.append(u)\n",
    "\n",
    "filt_utts = sorted(filt_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./fisher/fisher_test/fisher_test_eval.ids\", \"w\") as out_f:\n",
    "    for u in filt_utts:\n",
    "        out_f.write(\"{0:s}\\n\".format(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_utts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_test_hyps[filt_utts[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./fisher/fisher_test/fisher_test_eval.ids\", \"w\") as out_f:\n",
    "    for u in filt_utts:\n",
    "        out_f.write(\"{0:s}\\n\".format(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_path = \"/disk/scratch/s1444673/zero/installs/kaldi/egs/swbd/s5c/swbd1_train_100k/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = np.load(\"/disk/scratch/s1444673/zero/installs/kaldi/egs/swbd/s5c/swbd1_train_100k/sw02054.np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha['sw02054-A_000204-000790'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_speech_segments(map_dict[cat], cat_speech_path, cat_out_path, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 1\n",
    "\n",
    "# %aimport basics\n",
    "# %aimport enc_dec\n",
    "\n",
    "from basics import *\n",
    "from enc_dec import *\n",
    "import prep_buckets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nmt_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_encoder_params(src_model, target_model):\n",
    "    target_model.CNN_0 = src_model.CNN_0\n",
    "    target_model.CNN_0_bn = src_model.CNN_0_bn\n",
    "    \n",
    "    target_model.CNN_1 = src_model.CNN_1\n",
    "    target_model.CNN_1_bn = src_model.CNN_1_bn\n",
    "    \n",
    "    target_model.L0_enc = src_model.L0_enc\n",
    "    target_model.L1_enc = src_model.L1_enc\n",
    "    target_model.L2_enc = src_model.L2_enc\n",
    "    \n",
    "    target_model.L0_rev_enc = src_model.L0_rev_enc\n",
    "    target_model.L1_rev_enc = src_model.L1_rev_enc\n",
    "    target_model.L2_rev_enc = src_model.L2_rev_enc    \n",
    "\n",
    "    return target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_attention_params(src_model, target_model):\n",
    "    target_model.attn_Wa = src_model.attn_Wa\n",
    "    target_model.context = src_model.context\n",
    "    return target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_decoder_params(src_model, target_model):\n",
    "    target_model.L0_dec = src_model.L0_dec\n",
    "    target_model.L1_dec = src_model.L1_dec\n",
    "    target_model.L2_dec = src_model.L2_dec\n",
    "    target_model.embed_dec = src_model.embed_dec\n",
    "    target_model.out = src_model.out\n",
    "    return target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_path = \"./experiments/nmt_asr/mboshi-kaldi_swbd1-gpfr_bpe_freeze-cnn\"\n",
    "m2_path = \"./experiments/nmt_asr/mboshi-kaldi_swbd1-gpfr_bpe_freeze-cnn_dummy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/group/project/lowres/work/miniconda3/envs/chainer3/lib/python3.6/site-packages/chainer/backends/cuda.py:95: UserWarning: cuDNN is not enabled.\n",
      "Please reinstall CuPy after you install cudnn\n",
      "(see https://docs-cupy.chainer.org/en/stable/install.html#install-cupy-with-cudnn-and-nccl).\n",
      "  'cuDNN is not enabled.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobias =  True\n",
      "nobias =  True\n",
      "cnn_out_dim = rnn_in_units =  512\n",
      "--------------------------------------------------------------------------------\n",
      "using randomly initialized embeddings\n",
      "--------------------------------------------------------------------------------\n",
      "using ADAM optimizer\n",
      "freezing: CNN_0\n",
      "freezing: CNN_0_bn\n",
      "freezing: CNN_1\n",
      "freezing: CNN_1_bn\n",
      "--------------------------------------------------------------------------------\n",
      "model found = \n",
      "./experiments/nmt_asr/mboshi-kaldi_swbd1-gpfr_bpe_freeze-cnn/seq2seq_1.model\n",
      "finished loading ..\n",
      "freezing: CNN_0\n",
      "freezing: CNN_0_bn\n",
      "freezing: CNN_1\n",
      "freezing: CNN_1_bn\n"
     ]
    }
   ],
   "source": [
    "_, model1, _, _, _ = check_model(m1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze = [\"CNN_0\", \"CNN_0_bn\", \"CNN_1\", \"CNN_1_bn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in freeze:\n",
    "    if l in model2.__dict__:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_components = ['CNN_0', 'CNN_0_bn', 'CNN_1', 'CNN_1_bn', \n",
    "                  'L0_enc', 'L1_enc', 'L2_enc', \n",
    "                  'L0_rev_enc', 'L1_rev_enc', 'L2_rev_enc']\n",
    "attn_components = ['attn_Wa', 'context']\n",
    "dec_components = ['L0_dec', 'L1_dec', 'L2_dec', 'embed_dec', 'out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobias =  True\n",
      "nobias =  True\n",
      "cnn_out_dim = rnn_in_units =  512\n",
      "--------------------------------------------------------------------------------\n",
      "using randomly initialized embeddings\n",
      "--------------------------------------------------------------------------------\n",
      "using ADAM optimizer\n",
      "freezing: CNN_0\n",
      "freezing: CNN_0_bn\n",
      "freezing: CNN_1\n",
      "freezing: CNN_1_bn\n",
      "--------------------------------------------------------------------------------\n",
      "model found = \n",
      "./experiments/nmt_asr/mboshi-kaldi_swbd1-gpfr_bpe_freeze-cnn_dummy/seq2seq_0.model\n",
      "finished loading ..\n",
      "freezing: CNN_0\n",
      "freezing: CNN_0_bn\n",
      "freezing: CNN_1\n",
      "freezing: CNN_1_bn\n"
     ]
    }
   ],
   "source": [
    "_, model2, _, m_cfg, _ = check_model(m2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(xp.all(model1.CNN_0.W.data == model2.CNN_0.W.data))\n",
    "print(xp.all(model1.L0_dec.lateral.W.data == model2.L0_dec.lateral.W.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model2.CNN_0.update_enabled)\n",
    "model2.CNN_0.disable_update()\n",
    "print(model2.CNN_0.update_enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.CNN_0.disable_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = copy_encoder_params(src_model=model1, target_model=model2)\n",
    "# model2 = copy_attention_params(src_model=model1, target_model=model2)\n",
    "model2 = copy_decoder_params(src_model=model1, target_model=model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fil = m_cfg['model_fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.save_npz(model_fil.replace(\".model\", \"_{0:d}.model\".format(25)), model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.embed_dec.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dec_components(m1, m2):\n",
    "    print(xp.all(m1.L0_dec.lateral.W.data == m2.L0_dec.lateral.W.data))\n",
    "    print(xp.all(m1.L0_dec.upward.W.data == m2.L0_dec.upward.W.data))\n",
    "    print(xp.all(m1.L0_dec.upward.b.data == m2.L0_dec.upward.b.data))\n",
    "    \n",
    "    print(xp.all(m1.L1_dec.lateral.W.data == m2.L1_dec.lateral.W.data))\n",
    "    print(xp.all(m1.L1_dec.upward.W.data == m2.L1_dec.upward.W.data))\n",
    "    print(xp.all(m1.L1_dec.upward.b.data == m2.L1_dec.upward.b.data))\n",
    "    \n",
    "    print(xp.all(m1.L2_dec.lateral.W.data == m2.L2_dec.lateral.W.data))\n",
    "    print(xp.all(m1.L2_dec.upward.W.data == m2.L2_dec.upward.W.data))\n",
    "    print(xp.all(m1.L2_dec.upward.b.data == m2.L2_dec.upward.b.data))\n",
    "    \n",
    "    print(xp.all(m1.out.W.data == m2.out.W.data))\n",
    "    print(xp.all(m1.embed_dec.W.data == m2.embed_dec.W.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.embed_dec.W[5:,:], model1.embed_dec.W[5:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dec_components(model1, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg_path = \"./es_w_cfg_1/model_cfg.json\"\n",
    "train_cfg_path = \"./es_w_cfg_1/train_cfg.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_cfg_path, \"r\") as model_f:\n",
    "        model_cfg = json.load(model_f)\n",
    "\n",
    "with open(train_cfg_path, \"r\") as train_f:\n",
    "        train_cfg = json.load(train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch, model, optimizer = check_model(model_cfg, train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict, vocab_dict, bucket_dict = get_data_dicts(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('speech2text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L0_dec.W.W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'fisher_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_dict=bucket_dict[key]\n",
    "m_dict = map_dict[key]\n",
    "vocab_dict=vocab_dict\n",
    "batch_size=25\n",
    "x_key=model_cfg['enc_key']\n",
    "y_key=model_cfg['dec_key']\n",
    "train=False\n",
    "cat_speech_path=os.path.join(model_cfg['data_path'], key)\n",
    "\n",
    "num_b = b_dict['num_b']\n",
    "width_b = b_dict['width_b']\n",
    "# b = num_b-1\n",
    "b = 9\n",
    "bucket = b_dict['buckets'][b]\n",
    "b_len = len(bucket)\n",
    "input_path = os.path.join(model_cfg['data_path'], model_cfg['train_set'])\n",
    "utt_list = bucket[0:0+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_b, b_len, width_b, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_list = bucket[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(utt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = get_batch(m_dict, x_key, y_key, utt_list, vocab_dict, ((b+1) * width_b), 200, \n",
    "                           input_path=input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data['X'].shape, batch_data['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = batch_data['y']\n",
    "y = F.swapaxes(y, 0, 1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = y.shape[1]\n",
    "loss = 0\n",
    "# ---------------------------------------------------------------------\n",
    "# initialize hidden states as a zero vector\n",
    "# ---------------------------------------------------------------------\n",
    "a_units = model.m_cfg['attn_units']\n",
    "ht = Variable(xp.zeros((batch_size, a_units), dtype=xp.float32))\n",
    "print(batch_size, ht.shape)\n",
    "decoder_input = y[0]\n",
    "print(decoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_id = F.dropout(model.embed_dec(decoder_input), ratio=model.m_cfg['rnn_dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_in = F.concat((embed_id, ht), axis=1)\n",
    "rnn_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L0_dec.W.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = rnn_in\n",
    "hs = model[model.rnn_dec[0]](hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bucket size={0:d}\".format(b_len))\n",
    "\n",
    "for i in range(0,batch_size, batch_size):\n",
    "    utt_list = bucket[i:i+batch_size]\n",
    "    batch_data = get_batch(m_dict, x_key, y_key, utt_list, vocab_dict, ((b+1) * width_b), 200, \n",
    "                           input_path=input_path)\n",
    "    print(i, batch_data['X'].shape, batch_data['y'].shape)\n",
    "    \n",
    "    with chainer.using_config('train', True): \n",
    "        cuda.get_device(model.gpuid).use()\n",
    "        p, loss = model.forward(X=batch_data['X'], y=batch_data['y'])\n",
    "    \n",
    "    model.cleargrads()\n",
    "    \n",
    "    loss.backward()\n",
    "    # loss_1.backward()\n",
    "\n",
    "    # model.addgrads(model_1)\n",
    "    optimizer.update()\n",
    "    \n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*80)\n",
    "print(\"EPOCH = {0:d}\".format(last_epoch+1))\n",
    "fsh_pred_sents, fsh_utts, loss = feed_model(map_dict[key],\n",
    "                  b_dict=bucket_dict[key],\n",
    "                  vocab_dict=vocab_dict,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  x_key=enc_key,\n",
    "                  y_key=dec_key,\n",
    "                  train=train,\n",
    "                  cat_speech_path=cat_speech_path, use_y=False, mini=False)\n",
    "\n",
    "print(\"{0:s} {1:s} mean loss={2:.4f}\".format(\"*\" * 10,\n",
    "                                    \"train\" if train else \"dev\",\n",
    "                                    loss))\n",
    "print(\"-\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh_pred_sents[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L0_dec.W.W.shape, model.L0_enc.W.W.shape, model.L0_rev_enc.W.W.shape, model.embed_dec.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256+256+256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L2_dec.W.W[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L2_dec.W.W.data[0,0] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add_weight_noise(0.,0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L2_dec.W.W[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L2_dec.W.update_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L2_dec.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L2_dec.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20000 * 64 / 138708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.random.normal(0, .125, (5,5), dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rnn_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L0_dec.W, model.L0_dec.W_r, model.L0_dec.W_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L0_dec.U, model.L0_dec.U_r, model.L0_dec.U_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L0_dec.U.W.shape, model.L0_dec.U.b.shape, model.L0_dec.U_r.W.shape, model.L0_dec.U_r.b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embed_dec.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.125 # mean and standard deviation\n",
    "\n",
    "for rnn_layer in model.rnn_enc + model.rnn_dec:\n",
    "    print(rnn_layer)\n",
    "    layer_shape = model[rnn_layer][\"W\"].W.shape\n",
    "    print(layer_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_dim = CNN_IN_DIM\n",
    "cnn_out_dim = 0\n",
    "for i, l in enumerate(cnn_filters):\n",
    "    cnn_out_dim += l[\"out_channels\"]\n",
    "    print(reduce_dim, l[\"stride\"][1])\n",
    "    reduce_dim = math.ceil(reduce_dim / l[\"stride\"][1])\n",
    "    print(reduce_dim)\n",
    "    print(l[\"out_channels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_IN_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_filters[-1][\"out_channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch_data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.expand_dims(x,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cleargrads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lstm1_or_gru0:\n",
    "    print(model.L1_dec.lateral.W.grad)\n",
    "else:\n",
    "    print(model.L1_dec.W.W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.attn_Wa.W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.out.W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lstm1_or_gru0:\n",
    "    print(model.L0_enc.lateral.W.grad)\n",
    "else:\n",
    "    print(model.L0_enc.W.W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_weights_grads(layer):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20, 10))\n",
    "    plt.axis('off')\n",
    "    weights = layer.data\n",
    "    grads = layer.grad\n",
    "    if gpuid >= 0:\n",
    "        weights = cuda.cupy.asnumpy(weights[:,:])\n",
    "        grads = cuda.cupy.asnumpy(grads[:,:])\n",
    "    # plt.imshow(weights, interpolation='none')\n",
    "    ax1 = sns.heatmap(weights, cmap=\"RdBu_r\", ax=ax1, xticklabels=False, yticklabels=False)\n",
    "    ax2 = sns.heatmap(grads, cmap=\"RdBu_r\", ax=ax2, xticklabels=False, yticklabels=False)\n",
    "    print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_weights_grads(model.L0_enc.W.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_weights_grads(model.L1_dec.W.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_weights_grads(model.out.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.min(model.CNN_0.W.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.nonzero(model.embed_dec.W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_key, y_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_c_utt_lens = []\n",
    "en_c_utt_lens = []\n",
    "total_num = 0\n",
    "for b in b_dict['buckets']:\n",
    "    print(len(b), end=', ')\n",
    "    print(max([len(m_dict[u]['es_w']) for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['es_c']) for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['es_c'])//6 for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['en_w']) for u in b]), end=', ')\n",
    "    print(max([len(m_dict[u]['en_c']) for u in b]), end=', ')\n",
    "    print(total_num, end=', ')\n",
    "    print(\"\")\n",
    "    total_num += len(b)\n",
    "    es_c_utt_lens.extend([len(m_dict[u]['es_c']) for u in b])\n",
    "    en_c_utt_lens.extend([len(m_dict[u]['en_c']) for u in b])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(es_c_utt_lens, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(en_c_utt_lens, bins=10, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * 10 * 20 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data['X'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_forward_deep_cnn(h):\n",
    "    # check and prepare for 2d convolutions\n",
    "    if CNN_TYPE == DEEP_2D_CNN:\n",
    "        h = F.expand_dims(h, 2)\n",
    "        # h = F.reshape(h, (h.shape[:2] + tuple([-1,SPEECH_DIM // 3])))\n",
    "    h = F.swapaxes(h,1,2)\n",
    "    print(h.shape)\n",
    "\n",
    "    for i, cnn_layer in enumerate(model.cnns):\n",
    "        h = model[cnn_layer](h)\n",
    "        print(h.shape)\n",
    "        # h = F.max_pooling_nd(h, ksize=cnn_max_pool[i],\n",
    "        #                      stride=cnn_max_pool[i],\n",
    "        #                      pad=max_pool_pad)\n",
    "        # batch normalization before non-linearity\n",
    "        if USE_BN:\n",
    "            bn_lname = '{0:s}_bn'.format(cnn_layer)\n",
    "            h = model[bn_lname](h)\n",
    "        h = F.relu(h)\n",
    "        print(h.shape)\n",
    "\n",
    "    # out dimension:\n",
    "    # batch size * num time frames after pooling * cnn out dim\n",
    "    if CNN_TYPE == DEEP_2D_CNN:\n",
    "        h = F.swapaxes(h,1,2)\n",
    "        h = F.reshape(h, h.shape[:2] + tuple([-1]))\n",
    "        h = F.rollaxis(h,1)\n",
    "    else:\n",
    "        h = F.rollaxis(h, 2)\n",
    "    print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = check_forward_deep_cnn(batch_data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.forward_deep_cnn(batch_data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.cnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_rnn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_enc(batch_data['X'])\n",
    "model.set_decoder_state()\n",
    "y = F.swapaxes(batch_data['y'], 0, 1)\n",
    "# with cmodel.forward_enc(batch_data['X'])\n",
    "# with chainer.using_config('train', True):\n",
    "#     myloss = model.decode_batch(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enc_states.shape, 1280 /2/3//4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embed_units*2, model.n_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.L0_dec.W.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.attn_Wa.W.shape, model.context.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = y.shape[1]\n",
    "ht = Variable(xp.zeros((batch_size, 2*model.n_units), dtype=xp.float32))\n",
    "print(ht.shape)\n",
    "for curr_word, next_word in zip(y, y[1:]):\n",
    "    embed_id = model.embed_dec(curr_word)\n",
    "    print(embed_id.shape, curr_word.shape)\n",
    "    rnn_in = F.concat((embed_id, ht), axis=1)\n",
    "    print(rnn_in.shape)\n",
    "    h = model.feed_rnn(rnn_in, model.rnn_dec)\n",
    "    cv, _ = model.compute_context_vector(h)\n",
    "    cv_hdec = F.concat((cv, h), axis=1)\n",
    "    ht = model.context(cv_hdec)\n",
    "    # batch normalization before non-linearity\n",
    "    if USE_BN:\n",
    "        ht = model.context_bn(ht)\n",
    "    ht = F.tanh(ht)\n",
    "\n",
    "    predicted_out = model.out(ht)\n",
    "    print(predicted_out.shape)\n",
    "    print(ht.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = xp.zeros((y.shape[1],model.n_units), dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.concat((embed_id, ht), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[model.rnn_enc[-1]].h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_decoder_state(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enc_states.shape, h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding batch matmul and matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = F.batch_matmul(model.enc_states, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enc_states[0].shape, h[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.matmul(model.enc_states[0], h[0])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = model.attn_Wa(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = F.batch_matmul(model.enc_states, ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_data['X']\n",
    "y = batch_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape, X[0,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L.Linear(69,10)\n",
    "l1.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = l1(X[0,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = L.BatchNormalization(10)\n",
    "bn1.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln1 = L.LayerNormalization(10)\n",
    "ln1.to_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking BN, LN on network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer normalization\n",
    "xp.mean(h.data,axis=1), xp.var(h.data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.mean(model.L1_dec_ln(h).data,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.mean(h.data,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_data['X']\n",
    "h = F.swapaxes(X,1,2)\n",
    "\n",
    "h = F.relu(model[model.cnns[0]](h))\n",
    "h = F.max_pooling_nd(h, ksize=cnn_max_pool[0],\n",
    "                                 stride=cnn_max_pool[0],\n",
    "                                 pad=max_pool_pad)\n",
    "# h = model.forward_deep_cnn(h)\n",
    "# print(h.shape)\n",
    "# h = F.rollaxis(h, 2)\n",
    "h = F.swapaxes(h,1,2)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huhu = L.BatchNormalization(256)\n",
    "huhu.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huhu(h[:,0,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.CNN_0_bn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape, model.CNN_2_bn.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.mean(h.data, axis=(0,1)), xp.var(h.data, axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xp.mean(model.CNN_2_bn(h).data[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.mean(h[0].data,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean and var across all inputs in the batch and the same dimension should be 0, and ~1 respectively\n",
    "\n",
    "The shape should be the number of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_bn = bn1(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.mean(h1.data,axis=0), xp.var(h1.data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.mean(h2_bn.data,axis=0), xp.var(h2_bn.data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_ln = ln1(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean and var across all layer activations within a batch should be 0, and ~1 respectively\n",
    "\n",
    "The shape should be the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.mean(h2_ln.data,axis=1), xp.var(h2_ln.data,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN across frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = xp.random.randn(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.expand_dims(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = F.reshape(a, (-1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.data[1,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = xp.load(\"fbank_out/fisher_train/20050908/20050908_182943_22_fsp-A-1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.reshape(a, (1,len(a),-1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.swapaxes(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0,0,:2,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2d_1 = L.Convolution2D(in_channels=None, \n",
    "                      out_channels=32, \n",
    "                      ksize=(3,3), \n",
    "                      stride=(2,2),pad=3//2)\n",
    "\n",
    "c2d_bn_1 = L.BatchNormalization(32)\n",
    "\n",
    "c2d_2 = L.Convolution2D(in_channels=None, \n",
    "                      out_channels=32, \n",
    "                      ksize=(3,3), \n",
    "                      stride=(2,2),pad=3//2)\n",
    "\n",
    "c2d_bn_2 = L.BatchNormalization(32)\n",
    "\n",
    "c2d_1.to_gpu()\n",
    "c2d_2.to_gpu()\n",
    "c2d_bn_1.to_gpu()\n",
    "c2d_bn_2.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_data['X']\n",
    "y = batch_data['y']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = F.reshape(X, (X.shape[:2] + tuple([-1,SPEECH_DIM // 3])))\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = F.swapaxes(h,1,2)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c2d_1(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2d_1.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_bn = c2d_bn_1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_bn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c2d_2(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2d_2.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bn = c2d_bn_1(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = F.swapaxes(d, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape[:2] + tuple([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = F.reshape(e, e.shape[:2] + tuple([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_1 = L.ConvolutionND(ndim=3,\n",
    "                        in_channels=1, \n",
    "                        out_channels=32, \n",
    "                        ksize=(3,3,3), \n",
    "                        stride=2,pad=3//2)\n",
    "\n",
    "cnd_2 = L.ConvolutionND(ndim=3,\n",
    "                        in_channels=1, \n",
    "                        out_channels=32, \n",
    "                        ksize=(3,3,3), \n",
    "                        stride=2,pad=3//2)\n",
    "\n",
    "cnd_1.to_gpu()\n",
    "cnd_2.to_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NStepBiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_enc = L.NStepGRU(2,SPEECH_DIM, hidden_units, DROPOUT_RATIO)\n",
    "ng_dec = L.NStepGRU(2,hidden_units, hidden_units, DROPOUT_RATIO)\n",
    "ng_enc.to_gpu()\n",
    "ng_dec.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = batch_data['X'][:,:20,:], batch_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,o = ng_enc(hx=None, xs=X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape, len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[:1].shape,h[-1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Variable(np.asarray(o))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd,od = ng_dec(hx=h,xs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sents, loss = feed_model(map_dict[key],\n",
    "                              b_dict=bucket_dict[key],\n",
    "                              vocab_dict=vocab_dict,\n",
    "                              batch_size=64,\n",
    "                              x_key=enc_key,\n",
    "                              y_key=dec_key,\n",
    "                              train=True,\n",
    "                              cat_speech_path=os.path.join(out_path, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(w.decode(),f) for w,f in vocab_dict['es_c']['freq'].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join([w.decode() for w in map_dict['fisher_train']['20050908_182943_22_fsp-B-7']['es_c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = cuda.cupy if gpuid >= 0 else np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab_dict[enc_key]['w2i']))\n",
    "print(len(vocab_dict[dec_key]['w2i']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpuid >= 0:\n",
    "    # print(\"here\")\n",
    "    cuda.get_device_from_id(gpuid).use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechEncoderDecoder()\n",
    "\n",
    "if gpuid >= 0:\n",
    "    cuda.get_device(gpuid).use()\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMIZER_ADAM1_SGD_0:\n",
    "    print(\"using ADAM optimizer\")\n",
    "    # optimizer = optimizers.Adam(alpha=0.001,\n",
    "    #                             beta1=0.9,\n",
    "    #                             beta2=0.999,\n",
    "    #                             eps=1e-08)\n",
    "    # optimizer = optimizers.AdaGrad()\n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(model)\n",
    "else:\n",
    "    print(\"using SGD optimizer\")\n",
    "    optimizer = optimizers.SGD(lr=0.01)\n",
    "    optimizer.setup(model)\n",
    "\n",
    "if WEIGHT_DECAY:\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(WD_RATIO))\n",
    "\n",
    "# gradient clipping\n",
    "optimizer.add_hook(chainer.optimizer.GradientClipping(threshold=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(map_dict['fisher_train']['20050908_182943_22_fsp-B-7']['en_w']))\n",
    "print(type(map_dict['fisher_dev']['20051009_182032_217_fsp-B-1']['en_w'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict['fisher_dev']['20051009_182032_217_fsp-B-1']['en_w'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_model(map_dict['fisher_train'], b_dict=bucket_dict['fisher_train'], \n",
    "           vocab_dict=vocab_dict, batch_size=BATCH_SIZE, \n",
    "           x_key=enc_key, y_key=dec_key, cat_speech_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = pickle.load(open(\"out/train_vocab.dict\", \"rb\"))\n",
    "vocab_dict['es_w']['w2i'][b'solas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict['fisher_train']['20050908_182943_22_fsp-B-7']['es_w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_sents), pred_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in b_shuffled:\n",
    "    bucket = bucket_dict['fisher_train']['buckets'][b]\n",
    "    b_len = len(bucket)\n",
    "    print(b_len)\n",
    "    for i in range(0,b_len, 32):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise simulation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map_dict['fisher_train'].keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = buckets_dict['train'][0]['X_fwd'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_var = np.full(test_batch.shape, 0.01, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(np.random.normal(0.0, .01, size=test_batch.shape).astype(xp.float32))\n",
    "noise.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_noise = test_batch + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch[0,0,:5], test_batch_noise[0,0,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for consistency in train/dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set([f.split(\".\")[0] for f in text_data['train'].keys()]), sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set([f.split(\".\")[0] for f in text_data['dev'].keys()]), sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fids = []\n",
    "for b in buckets_dict[\"train\"]:\n",
    "    train_fids.extend(b['f'])\n",
    "dev_fids = []\n",
    "for b in buckets_dict[\"dev\"]:\n",
    "    dev_fids.extend(b['f'])\n",
    "print(len(train_fids), len(dev_fids))\n",
    "print(set([f.split(\".\")[0] for f in train_fids]), sep=\", \")\n",
    "print(set([f.split(\".\")[0] for f in dev_fids]), sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data['train'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ids, en_ids = predict(4,2, cat=\"dev\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fil_old = 'small/seq2seq_sen-4000_hwy4-dec2_emb-512-h-512__word_gru_sspkr_drpt-0_noise-0.20_l2-0.001_cnn-num100-range9-199-20-pool900_10.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $model_fil_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.load_npz(model_fil_old, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pplx_new = compute_pplx(cat=\"dev\", num_sent=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ids, en_ids = predict(3,2, cat=\"train\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ids, en_ids = predict(3,2, cat=\"dev\", display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create wavs for dev, dev2 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict['fisher_dev']['20051025_212334_337_fsp-B-39']['seg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_segments = list(map_dict['fisher_dev'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'20051025_212334_337_fsp-B-39'.rsplit('-',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_segments[0].rsplit('-',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_segments = set([l.rsplit('-',1)[0] for l in list_of_segments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set_of_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sph2pipe_path = '''/disk/scratch/s1444673/zero/installs/kaldi/egs/fisher_callhome_spanish/s5/../../../tools/sph2pipe_v2.5/sph2pipe'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"callhome_fbank_out/wav.scp\", \"r\") as wavs_f, open(\"callhome_fbank_out/wavs/dev_wavs.scp\", \"w\") as dev_wavs_f:\n",
    "    for line in wavs_f:\n",
    "        for seg in set_of_segments:\n",
    "            if seg in line:\n",
    "#                 print(seg)\n",
    "                out_line =line.split(\" \",1)[1].replace(' |', \" > {0:s}.wav\".format(seg))\n",
    "                dev_wavs_f.write(out_line)\n",
    "#                 subprocess.call([sph2pipe_path, \"-f\", \"wav\", \"-p\", \"-c\", \"1\", ])\n",
    "\n",
    "#         if any(x in line for x in set_of_segments):\n",
    "#             print(line.split(\" \",1)[1])\n",
    "#             dev_wavs_f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = \"callhome_fbank_out/wavs/20051009_182032_217_fsp-A.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = scipy.io.wavfile.read(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict['fisher_dev']['20051009_182032_217_fsp-B-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(haha[1][:20000], rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.load(\"callhome_fbank_out/wavs/20051009_182032_217_fsp-A.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
