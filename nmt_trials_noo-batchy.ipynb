{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport basics\n",
    "%aimport nn_config\n",
    "%aimport enc_dec\n",
    "\n",
    "\n",
    "from basics import *\n",
    "from nn_config import *\n",
    "from enc_dec import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = cuda.cupy if gpuid >= 0 else np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_data = pickle.load(open(text_data_dict, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SpeechEncoderDecoder(SPEECH_DIM, vocab_size_en, num_layers_enc, num_layers_dec,\n",
    "                               hidden_units, gpuid, attn=use_attn)\n",
    "if gpuid >= 0:\n",
    "    cuda.get_device(gpuid).use()\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('es_speech_to_en_char_better/train_17394sen_4-2layers_512units_callhome_callhome_es_en_1.log',\n",
       " {'en': '../../corpora/callhome/uttr_fa_vad_wavs/train.en',\n",
       "  'fr': '../../corpora/callhome/uttr_fa_vad_wavs/speech_train.es'},\n",
       " {'en': '../../corpora/callhome/uttr_fa_vad_wavs/dev.en',\n",
       "  'fr': '../../corpora/callhome/uttr_fa_vad_wavs/speech_dev.es'},\n",
       " {'en': '../../corpora/callhome/uttr_fa_vad_wavs/test.en',\n",
       "  'fr': '../../corpora/callhome/uttr_fa_vad_wavs/speech_test.es'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_train_fil_name, text_fname, dev_fname, test_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment\n",
      "num sentences=13137 and num epochs=0\n"
     ]
    }
   ],
   "source": [
    "%aimport nmt_trials\n",
    "from nmt_trials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into 34 buckets, each of width=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 2519/13137 [00:07<00:27, 381.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file=053.181 has a nan value, fr len=1, en len=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13137/13137 [00:36<00:00, 359.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving bucket data\n"
     ]
    }
   ],
   "source": [
    "buckets, bucket_lengths = populate_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 840)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25*32, 24*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True, dtype=bool)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, en, sf = get_data_item('053.181')\n",
    "xp.isnan(xp.sum(sf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buck_indx = 23\n",
    "i = 0\n",
    "batch_size = 50\n",
    "\n",
    "pad_size_speech = (buck_indx+1) * SPEECH_BUCKET_WIDTH\n",
    "pad_size_en = min(bucket_lengths[buck_indx][3], MAX_EN_LEN)\n",
    "\n",
    "src_lim = pad_size_speech\n",
    "tar_lim = pad_size_en\n",
    "\n",
    "sp_files_in_batch = [t[0] for t in buckets[buck_indx][i:i+batch_size]]\n",
    "\n",
    "# get the next batch of data\n",
    "batch_data = []\n",
    "for sp_fil in sp_files_in_batch:\n",
    "    _, en_ids, speech_feat = get_data_item(sp_fil, cat=\"train\")\n",
    "    # print(speech_feat.shape, len(en_ids))\n",
    "    batch_data.append((speech_feat[:pad_size_speech], en_ids[:pad_size_en]))\n",
    "\n",
    "# compute loss\n",
    "# loss = model.encode_decode_train_batch(batch_data, pad_size_speech, pad_size_en, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = len(batch_data)\n",
    "in_shape_r, in_shape_c = batch_data[0][0].shape\n",
    "\n",
    "fwd_encoder_batch = xp.full((batch_size, pad_size_speech, in_shape_c), PAD_ID, dtype=xp.float32)\n",
    "rev_encoder_batch = xp.full((batch_size, pad_size_speech, in_shape_c), PAD_ID, dtype=xp.float32)\n",
    "decoder_batch = xp.full((batch_size, pad_size_en+2), PAD_ID, dtype=xp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, (src, tar) in enumerate(batch_data):\n",
    "    fwd_encoder_batch[i] = model.pad_array(src, src_lim)\n",
    "    rev_encoder_batch[i] = model.pad_array(xp.flip(src, axis=0), src_lim)\n",
    "\n",
    "    tar_data = [GO_ID] + tar + [EOS_ID]\n",
    "    decoder_batch[i] = model.pad_list(tar_data, tar_lim+2, at_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fwd_encoder_batch = xp.swapaxes(fwd_encoder_batch, 0,1)\n",
    "rev_encoder_batch = xp.swapaxes(rev_encoder_batch, 0,1)\n",
    "decoder_batch = xp.swapaxes(decoder_batch, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_FWD_STATES = model.encode_speech_batch_lstm(fwd_encoder_batch, model.lstm_enc, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_REV_STATES = model.encode_speech_batch_lstm(rev_encoder_batch, model.lstm_rev_enc, train)\n",
    "# reverse the states to align them with forward encoder\n",
    "L_REV_STATES = xp.flip(L_REV_STATES, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "return_shape = L_FWD_STATES.shape\n",
    "model.enc_states = F.concat((L_FWD_STATES, L_REV_STATES), axis=2)\n",
    "model.enc_states = F.swapaxes(model.enc_states, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<variable at 0x7fd2553e5cc0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode_decode_train_batch(batch_data, pad_size_speech, pad_size_en, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_FWD_STATES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pad_size_speech / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_size, batch_size, in_dim = fwd_encoder_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(in_size, batch_size, in_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
