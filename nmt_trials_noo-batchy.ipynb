{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callhome es-en word level configuration\n",
      "translating es to en\n",
      "vocab size, en=51, fr=51\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport basics\n",
    "%aimport nn_config\n",
    "%aimport enc_dec\n",
    "\n",
    "\n",
    "from basics import *\n",
    "from nn_config import *\n",
    "from enc_dec import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = cuda.cupy if gpuid >= 0 else np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_data = pickle.load(open(text_data_dict, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SpeechEncoderDecoder(SPEECH_DIM, vocab_size_en, num_layers_enc, num_layers_dec,\n",
    "                               hidden_units, gpuid, attn=use_attn)\n",
    "if gpuid >= 0:\n",
    "    cuda.get_device(gpuid).use()\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('es_speech_to_en_char_model/train_17394sen_4-2layers_128units_es_en_speech2text_batches_callhome_es_en_1.log',\n",
       " {'en': '../../corpora/callhome/uttr_fa_vad_wavs/train.en',\n",
       "  'fr': '../../corpora/callhome/uttr_fa_vad_wavs/speech_train.es'},\n",
       " {'en': '../../corpora/callhome/uttr_fa_vad_wavs/dev.en',\n",
       "  'fr': '../../corpora/callhome/uttr_fa_vad_wavs/speech_dev.es'},\n",
       " {'en': '../../corpora/callhome/uttr_fa_vad_wavs/test.en',\n",
       "  'fr': '../../corpora/callhome/uttr_fa_vad_wavs/speech_test.es'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_train_fil_name, text_fname, dev_fname, test_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment\n",
      "num sentences=1000 and num epochs=10\n"
     ]
    }
   ],
   "source": [
    "%aimport nmt_trials\n",
    "from nmt_trials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 69/13137 [00:00<00:18, 689.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into 35 buckets, each of width=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2683/13137 [00:01<00:06, 1563.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file=053.181 has a nan value, fr len=1, en len=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13137/13137 [00:09<00:00, 1371.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving bucket data\n"
     ]
    }
   ],
   "source": [
    "buckets, bucket_lengths = populate_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 840)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25*32, 24*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE, BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True, dtype=bool)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, en, sf = get_data_item('053.181')\n",
    "xp.isnan(xp.sum(sf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for sp_fil in text_data[\"train\"].keys():\n",
    "#     _, en, sf = get_data_item(sp_fil)\n",
    "#     if xp.isnan(xp.sum(sf)) == True:\n",
    "#         print(sp_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment\n",
      "num sentences=1000 and num epochs=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1, loss=660.2311, mean loss=64.0069: 101it [02:14,  2.04s/it]                        \n"
     ]
    }
   ],
   "source": [
    "batch_training(BATCH_SIZE*10, BATCH_SIZE, buckets, bucket_lengths, SPEECH_BUCKET_WIDTH, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.L0_enc.lateral.W.data[:2,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.enc_states.shape, model.L1_dec.h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = F.batch_matmul(model.enc_states, model[model.lstm_dec[-1]].h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = F.batch_matmul(F.swapaxes(model.enc_states, 0, 1), model[model.lstm_dec[-1]].h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F.reshape(weights,(weights.shape[0],weights.shape[1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F.softmax(xp.array([[-0.01054492], [-0.00358161],[ 0.00333601]])).data\n",
    "xp.array([[-0.01054492], [-0.00358161],[ 0.00333601]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights.data, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.mask.shape, model.minf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F.softmax(F.reshape(weights,(weights.shape[0],weights.shape[1]))).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = F.softmax(weights,True)\n",
    "alphas.data, alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ha = F.swapaxes(model.enc_states, 0,1)\n",
    "haha = F.swapaxes(ha, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.enc_states.shape, haha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F.batch_matmul(haha, alphas).shape, F.squeeze(F.batch_matmul(haha, alphas),axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = F.reshape(F.batch_matmul(F.swapaxes(model.enc_states, 2, 1), alphas), shape=(batch_size, n_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict(s=0, num=1, cat=\"train\", display=True, plot=False, p_filt=0, r_filt=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(b\" \".join(get_ids(text_data[\"train\"][\"041.004\"][\"en\"])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward_states = model[model.lstm_enc[-1]].h\n",
    "# backward_states = model[model.lstm_rev_enc[-1]].h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.enc_states = F.concat((forward_states, backward_states), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_loop(num_training=1000, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavs = []\n",
    "wavs.append(xp.load(os.path.join(speech_dir, \"041.001\"+speech_extn)))\n",
    "wavs.append(xp.load(os.path.join(speech_dir, \"041.004\"+speech_extn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[l.shape for l in wavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_arr = xp.zeros((3,120), dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavs[1].dtype, zero_arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# xp.vstack((wavs[1], zero_arr))\n",
    "wavs[1].shape, zero_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavs.append(pad_array(wavs[1], 1000, at_start=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xp.concatenate((wavs[1], zero_arr), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavs[1][:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xp.pad(wavs[1], pad_width=(0,100), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_buckets(bucket_lengths, width_b = SPEECH_BUCKET_WIDTH):\n",
    "    headings = (\"ix\", \"len b\", \"num\", \"max fr\", \"avg fr\", \"max en\", \"avg en\")\n",
    "    print(\"{0:3s} | {1:5s} | {2:5s} | {3:6s} | {4:8s} | {5:6s} | {6:8s}\".format(*headings))\n",
    "    print(\"\\n\".join([\"{0:3d} | {1:5d} | {2:5d} | {3:6d} | {4:8.0f} | {5:6d} | {6:8.0f}\".format(i[0], (i[0]+1)*width_b, *i[1]) for i in list(bucket_lengths.items())]))\n",
    "\n",
    "\n",
    "def populate_buckets(width_b = SPEECH_BUCKET_WIDTH, \n",
    "                     num_b = SPEECH_NUM_BUCKETS, \n",
    "                     speech=True, \n",
    "                     num_sent=NUM_TRAINING_SENTENCES,\n",
    "                     filname_b=speech_bucket_data_fname,\n",
    "                     cat=\"train\", display=False):\n",
    "    \n",
    "    buckets = [[] for i in range(num_b)]\n",
    "    \n",
    "    print(\"Splitting data into {0:d} buckets, each of width={1:d}\".format(num_b, width_b))\n",
    "\n",
    "    with tqdm(total=num_sent) as pbar:\n",
    "        for i, sp_fil in enumerate(sorted(list(text_data[cat].keys()))[:num_sent]):\n",
    "\n",
    "            fr_ids, en_ids, speech_feat = get_data_item(sp_fil, cat=cat)\n",
    "\n",
    "            len_en = len(en_ids)\n",
    "            len_fr = len(fr_ids)\n",
    "            len_speech = len(speech_feat)\n",
    "            \n",
    "            indx_b = min(num_b-1, len_speech // width_b)\n",
    "\n",
    "            buckets[indx_b].append((sp_fil, len_speech, len_fr, len_en))\n",
    "\n",
    "            pbar.update(1)\n",
    "    \n",
    "    bucket_lengths = {i:(len(l), \n",
    "                    max(l, key=lambda t:t[2])[2],\n",
    "                    np.mean([i[2]for i in l]),\n",
    "                    max(l, key=lambda t:t[3])[3],\n",
    "                    np.mean([i[3]for i in l]))\n",
    "                     for i, l in enumerate(buckets)}\n",
    "\n",
    "    if display:\n",
    "        display_buckets(bucket_lengths)\n",
    "\n",
    "    # Saving bucket data\n",
    "    print(\"Saving bucket data\")\n",
    "    pickle.dump(buckets, open(filname_b, \"wb\"))\n",
    "    return buckets, bucket_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b, bucket_lengths = populate_buckets(display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = [0 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = haha[:30]\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bucket_lengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
