{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "translating es to en\n",
      "callhome es-en word level configuration\n",
      "vocab size, en=51, fr=51\n"
     ]
    },
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (enc_dec.py, line 62)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2862\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-2-762a8d8f0f2c>\"\u001b[0m, line \u001b[1;32m6\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    get_ipython().magic('aimport enc_dec')\n",
      "  File \u001b[1;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2146\u001b[0m, in \u001b[1;35mmagic\u001b[0m\n    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \u001b[1;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2067\u001b[0m, in \u001b[1;35mrun_line_magic\u001b[0m\n    result = fn(*args,**kwargs)\n",
      "  File \u001b[1;32m\"<decorator-gen-126>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35maimport\u001b[0m\n",
      "  File \u001b[1;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/site-packages/IPython/core/magic.py\"\u001b[0m, line \u001b[1;32m187\u001b[0m, in \u001b[1;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[1;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/site-packages/IPython/extensions/autoreload.py\"\u001b[0m, line \u001b[1;32m496\u001b[0m, in \u001b[1;35maimport\u001b[0m\n    top_module, top_name = self._reloader.aimport_module(_module)\n",
      "  File \u001b[1;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/site-packages/IPython/extensions/autoreload.py\"\u001b[0m, line \u001b[1;32m179\u001b[0m, in \u001b[1;35maimport_module\u001b[0m\n    import_module(module_name)\n",
      "  File \u001b[1;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/importlib/__init__.py\"\u001b[0m, line \u001b[1;32m126\u001b[0m, in \u001b[1;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m978\u001b[0m, in \u001b[1;35m_gcd_import\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m961\u001b[0m, in \u001b[1;35m_find_and_load\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m950\u001b[0m, in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m655\u001b[0m, in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m674\u001b[0m, in \u001b[1;35mexec_module\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m781\u001b[0m, in \u001b[1;35mget_code\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m741\u001b[0m, in \u001b[1;35msource_to_code\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0;36m, line \u001b[0;32m205\u001b[0;36m, in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/afs/inf.ed.ac.uk/group/project/lowres/work/chainer2/speech2text/enc_dec.py\"\u001b[0;36m, line \u001b[0;32m62\u001b[0m\n\u001b[0;31m    def init_rnn_model(self, scale):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport basics\n",
    "%aimport nn_config\n",
    "%aimport enc_dec\n",
    "\n",
    "\n",
    "from basics import *\n",
    "from nn_config import *\n",
    "from enc_dec import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = cuda.cupy if gpuid >= 0 else np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pickle.load(open(text_data_dict, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpuid >= 0:\n",
    "    # print(\"here\")\n",
    "    cuda.get_device(gpuid).use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechEncoderDecoder(SPEECH_DIM, vocab_size_en, num_layers_enc, num_layers_dec,\n",
    "                               hidden_units, gpuid, attn=use_attn)\n",
    "if gpuid >= 0:\n",
    "    cuda.get_device(gpuid).use()\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_fil_name, text_fname, dev_fname, test_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport nmt_trials\n",
    "from nmt_trials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets, bucket_lengths = populate_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25*32, 24*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, en, sf = get_data_item('053.181')\n",
    "xp.isnan(xp.sum(sf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buck_indx = 23\n",
    "i = 0\n",
    "batch_size = 50\n",
    "\n",
    "pad_size_speech = (buck_indx+1) * SPEECH_BUCKET_WIDTH\n",
    "pad_size_en = min(bucket_lengths[buck_indx][3], MAX_EN_LEN)\n",
    "\n",
    "src_lim = pad_size_speech\n",
    "tar_lim = pad_size_en\n",
    "\n",
    "sp_files_in_batch = [t[0] for t in buckets[buck_indx][i:i+batch_size]]\n",
    "\n",
    "# get the next batch of data\n",
    "batch_data = []\n",
    "for sp_fil in sp_files_in_batch:\n",
    "    _, en_ids, speech_feat = get_data_item(sp_fil, cat=\"train\")\n",
    "    # print(speech_feat.shape, len(en_ids))\n",
    "    batch_data.append((speech_feat[:pad_size_speech], en_ids[:pad_size_en]))\n",
    "\n",
    "# compute loss\n",
    "# loss = model.encode_decode_train_batch(batch_data, pad_size_speech, pad_size_en, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(batch_data)\n",
    "in_shape_r, in_shape_c = batch_data[0][0].shape\n",
    "\n",
    "fwd_encoder_batch = xp.full((batch_size, pad_size_speech, in_shape_c), PAD_ID, dtype=xp.float32)\n",
    "rev_encoder_batch = xp.full((batch_size, pad_size_speech, in_shape_c), PAD_ID, dtype=xp.float32)\n",
    "decoder_batch = xp.full((batch_size, pad_size_en+2), PAD_ID, dtype=xp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src, tar) in enumerate(batch_data):\n",
    "    fwd_encoder_batch[i] = model.pad_array(src, src_lim)\n",
    "    rev_encoder_batch[i] = model.pad_array(xp.flip(src, axis=0), src_lim)\n",
    "\n",
    "    tar_data = [GO_ID] + tar + [EOS_ID]\n",
    "    decoder_batch[i] = model.pad_list(tar_data, tar_lim+2, at_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fwd_encoder_batch = xp.swapaxes(fwd_encoder_batch, 0,1)\n",
    "rev_encoder_batch = xp.swapaxes(rev_encoder_batch, 0,1)\n",
    "decoder_batch = xp.swapaxes(decoder_batch, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_FWD_STATES = model.encode_speech_batch_lstm(fwd_encoder_batch, model.lstm_enc, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_REV_STATES = model.encode_speech_batch_lstm(rev_encoder_batch, model.lstm_rev_enc, train)\n",
    "# reverse the states to align them with forward encoder\n",
    "L_REV_STATES = xp.flip(L_REV_STATES, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_shape = L_FWD_STATES.shape\n",
    "model.enc_states = F.concat((L_FWD_STATES, L_REV_STATES), axis=2)\n",
    "model.enc_states = F.swapaxes(model.enc_states, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encode_decode_train_batch(batch_data, pad_size_speech, pad_size_en, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_FWD_STATES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size_speech / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_size, batch_size, in_dim = fwd_encoder_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_size, batch_size, in_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_feats = xp.load(os.path.join(speech_dir, \"train.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = speech_feats[\"041.001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = xp.array([[2,-2], [1,-1], [3,-3]], dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meh = F.expand_dims(haha.swapaxes(0,1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_out_size(i, p, k):\n",
    "    o = (i-k) + 2*p + 1\n",
    "    print(\"cnn out = {0:d}\".format(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_width = 2\n",
    "pad = k_width // 2\n",
    "# pad = k_width - 1\n",
    "pad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpuid >= 0:\n",
    "    # print(\"here\")\n",
    "    cuda.get_device(gpuid).use()\n",
    "c1 = L.ConvolutionND(ndim=1, in_channels=SPEECH_DIM, out_channels=1, ksize=k_width, pad=pad).to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = meh.shape[2]\n",
    "out_shape = (i-k_width) + 2*pad + 1\n",
    "print(i, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r2\n",
    "ha = c1(meh)\n",
    "print(ha.shape)\n",
    "print(ha.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test with small arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_test = xp.array([[2,-2,-5], [1,-1,-10], [3,-3,-9], [4,-4,-12]], dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  2.,  -2.,  -5.],\n",
       "        [  1.,  -1., -10.],\n",
       "        [  3.,  -3.,  -9.],\n",
       "        [  4.,  -4., -12.]], dtype=float32), (4, 3))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_test, mini_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_var = F.expand_dims(mini_test.swapaxes(0,1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 4)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_k = 3; mini_pad = mini_k // 2\n",
    "minic1 = L.ConvolutionND(ndim=1, in_channels=3, out_channels=5, ksize=2, stride=1, pad=1).to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn out = 5\n"
     ]
    }
   ],
   "source": [
    "cnn_out_size(i=4, k=2, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 2)\n",
      "[[[ 0.18660849 -0.03519266]\n",
      "  [-0.3809438  -0.05283932]\n",
      "  [-0.15335082 -0.06658217]]\n",
      "\n",
      " [[ 0.11922466  0.33550972]\n",
      "  [-0.05792021 -0.04456493]\n",
      "  [-0.9256264  -1.0981313 ]]\n",
      "\n",
      " [[-0.53644639 -0.42481604]\n",
      "  [-0.17755114  0.88369918]\n",
      "  [ 0.23915586  0.03831255]]\n",
      "\n",
      " [[-0.02067855 -0.08494393]\n",
      "  [-0.23605981  0.50130999]\n",
      "  [-0.46147168 -0.84219682]]\n",
      "\n",
      " [[ 0.04642114 -0.38426223]\n",
      "  [ 0.00247118 -0.37618864]\n",
      "  [-0.2522822   0.42013261]]]\n"
     ]
    }
   ],
   "source": [
    "print(minic1.W.shape)\n",
    "print(minic1.W.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = minic1.W.data[0]\n",
    "one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2., -2., -5.], dtype=float32),\n",
       " array([  1.,  -1., -10.], dtype=float32))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_test[0], mini_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = one[0][0]*mini_test[0][0]\n",
    "h2 = one[1][0]*mini_test[0][1]\n",
    "h3 = one[2][0]*mini_test[0][2]\n",
    "h4 = one[0][1]*mini_test[1][0]\n",
    "h5 = one[1][1]*mini_test[1][1]\n",
    "h6 = one[2][1]*mini_test[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.5853271484375, dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([h1, h2, h3, h4, h5, h6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_cnn_out = minic1(mini_var).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5, 5), array([[[  0.36820415,   2.58532691,   2.75324011,   3.95238686,\n",
       "            4.11041927],\n",
       "         [  6.25080585,  16.34380913,  20.45681572,  23.55994606,\n",
       "           11.81609631],\n",
       "         [ -2.80859303,  -3.60521054,  -7.02081251,  -8.92289925,\n",
       "           -4.30545139],\n",
       "         [  3.03847623,  10.57383537,  10.65110779,  12.5607357 ,\n",
       "            6.39918518],\n",
       "         [ -2.11681032,  -2.86008883,  -1.23864245,  -2.67149591,\n",
       "            3.20318627]]], dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_cnn_out.shape, mini_cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/mtenv/lib/python3.6/site-packages/chainer/utils/experimental.py:104: FutureWarning: chainer.functions.pooling.MaxPoolingND is experimental. The interface can change in the future.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.50540251,  0.70818657,  0.9858464 ,  0.9858464 ,  0.68322808],\n",
       "        [-0.81462538, -0.81462538, -2.12726021, -2.12726021, -2.71596646]]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.max_pooling_nd(mini_cnn_out, ksize=2, stride=1, pad=mini_pad).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
