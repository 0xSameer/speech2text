{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translating es to en\n",
      "callhome es-en word level configuration\n",
      "vocab size, en=5691, fr=8904\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport basics\n",
    "%aimport nn_config\n",
    "%aimport enc_dec\n",
    "\n",
    "\n",
    "from basics import *\n",
    "from nn_config import *\n",
    "from enc_dec import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = cuda.cupy if gpuid >= 0 else np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data = pickle.load(open(text_data_dict, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpuid >= 0:\n",
    "    # print(\"here\")\n",
    "    cuda.get_device(gpuid).use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SpeechEncoderDecoder(SPEECH_DIM, vocab_size_en, num_layers_enc, num_layers_dec,\n",
    "                               hidden_units, gpuid, attn=use_attn)\n",
    "if gpuid >= 0:\n",
    "    cuda.get_device(gpuid).use()\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_train_fil_name, text_fname, dev_fname, test_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%aimport nmt_trials\n",
    "from nmt_trials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buckets, bucket_lengths = populate_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "25*32, 24*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, en, sf1 = get_data_item('053.182')\n",
    "_, en, sf2 = get_data_item('053.183')\n",
    "xp.isnan(xp.sum(sf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf1.shape, sf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, sp1 = get_data_item(\"041.002\", \"train\")\n",
    "_, _, sp2 = get_data_item(\"041.004\", \"train\")\n",
    "batch_data = [sp1[:100], sp2[:100]]\n",
    "print(sp1.shape, sp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from chainer.utils import type_check\n",
    "# from chainer import function\n",
    "# class PadSequence(function.Function):\n",
    "\n",
    "#     def __init__(self, length, padding):\n",
    "#         self.length = length\n",
    "#         self.padding = padding\n",
    "\n",
    "#     def check_type_forward(self, in_types):\n",
    "#         type_check.expect(in_types.size() > 0)\n",
    "\n",
    "#         for in_type in in_types:\n",
    "#             type_check.expect(\n",
    "#                 in_type.ndim > 0,\n",
    "#                 in_type.shape[1:] == in_types[0].shape[1:],\n",
    "#                 in_type.dtype == in_types[0].dtype)\n",
    "\n",
    "#         if self.length is not None:\n",
    "#             for in_type in in_types:\n",
    "#                 type_check.expect(in_type.shape[0] <= self.length)\n",
    "\n",
    "#     def forward(self, xs):\n",
    "#         xp = cuda.get_array_module(*xs)\n",
    "\n",
    "#         if self.length is None:\n",
    "#             length = max(len(x) for x in xs)\n",
    "#         else:\n",
    "#             length = self.length\n",
    "\n",
    "#         shape = (len(xs), length) + xs[0].shape[1:]\n",
    "#         y = xp.empty(shape, xs[0].dtype)\n",
    "#         if length == 0:\n",
    "#             return y,\n",
    "\n",
    "#         if xp is np or any(not x._c_contiguous for x in xs):\n",
    "#             for i, x in enumerate(xs):\n",
    "#                 l = len(x)\n",
    "#                 if l == length:\n",
    "#                     y[i] = x\n",
    "#                 else:\n",
    "#                     y[i, 0:l] = x\n",
    "#                     y[i, l:] = self.padding\n",
    "#         else:\n",
    "#             # This code assumes that all arrays are c_contiguous\n",
    "#             ptr_shape = (Ellipsis,) + (None,) * xs[0].ndim\n",
    "#             ptrs = cuda.cupy.array([x.data for x in xs], 'L')[ptr_shape]\n",
    "#             lengths = cuda.cupy.array([len(x) for x in xs], 'i')[ptr_shape]\n",
    "#             base = np.prod(xs[0].shape[1:], dtype='i')\n",
    "#             cuda.elementwise(\n",
    "#                 'P ptr, int32 length, T pad, int32 base, int32 max_length',\n",
    "#                 'T y',\n",
    "#                 '''\n",
    "#                 int d = i / base % max_length;\n",
    "#                 if (d < length) {\n",
    "#                   y = reinterpret_cast<const T*>(ptr)[i % (base * max_length)];\n",
    "#                 } else {\n",
    "#                   y = pad;\n",
    "#                 }\n",
    "#                 ''',\n",
    "#                 'pad_sequence_fwd'\n",
    "#             )(ptrs, lengths, self.padding, base, length, y)\n",
    "\n",
    "#         return y,\n",
    "\n",
    "#     def backward(self, xs, grad):\n",
    "#         xp = cuda.get_array_module(*xs)\n",
    "#         gs = grad[0]\n",
    "#         if gs.size == 0:\n",
    "#             # `split` in NumPy 1.9 behaves inconsistently when size is zero.\n",
    "#             gs = [gs]\n",
    "#         else:\n",
    "#             gs = xp.split(gs, len(xs), axis=0)\n",
    "#         return tuple([g[0, 0:len(x)] for g, x in six.moves.zip(gs, xs)])\n",
    "\n",
    "\n",
    "# def pad_sequence(xs, length=None, padding=0):\n",
    "#     \"\"\"Pad given arrays to make a matrix.\n",
    "#     Args:\n",
    "#         xs (list of ~chainer.Variable): Variables you want to concatenate.\n",
    "#         length (None or int): Size of the first dimension of a padded array.\n",
    "#             If it is ``None``, the longest size of the first dimension of\n",
    "#             ``xs`` is used.\n",
    "#         padding (int or float): Value to fill.\n",
    "#     Returns:\n",
    "#         ~chainer.Variable: It returns a padded matrix. Its shape is\n",
    "#             ``(n, length, ...)``, where ``n == len(xs)``.\n",
    "#     \"\"\"\n",
    "#     return PadSequence(length, padding)(*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hahaha = xp.array([[1,2],[3,4],[5,6]], dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.flipud(hahaha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = F.pad_sequence(xs=(batch_data), length=100, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = F.pad_sequence(ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buck_indx = 23\n",
    "i = 0\n",
    "batch_size = 50\n",
    "\n",
    "pad_size_speech = (buck_indx+1) * SPEECH_BUCKET_WIDTH\n",
    "pad_size_en = min(bucket_lengths[buck_indx][3], MAX_EN_LEN)\n",
    "\n",
    "src_lim = pad_size_speech\n",
    "tar_lim = pad_size_en\n",
    "\n",
    "sp_files_in_batch = [t[0] for t in buckets[buck_indx][i:i+batch_size]]\n",
    "\n",
    "# get the next batch of data\n",
    "batch_data = []\n",
    "for sp_fil in sp_files_in_batch:\n",
    "    _, en_ids, speech_feat = get_data_item(sp_fil, cat=\"train\")\n",
    "    # print(speech_feat.shape, len(en_ids))\n",
    "    batch_data.append((speech_feat[:pad_size_speech], en_ids[:pad_size_en]))\n",
    "\n",
    "# compute loss\n",
    "# loss = model.encode_decode_train_batch(batch_data, pad_size_speech, pad_size_en, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = len(batch_data)\n",
    "in_shape_r, in_shape_c = batch_data[0][0].shape\n",
    "\n",
    "fwd_encoder_batch = xp.full((batch_size, pad_size_speech, in_shape_c), PAD_ID, dtype=xp.float32)\n",
    "rev_encoder_batch = xp.full((batch_size, pad_size_speech, in_shape_c), PAD_ID, dtype=xp.float32)\n",
    "decoder_batch = xp.full((batch_size, pad_size_en+2), PAD_ID, dtype=xp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (src, tar) in enumerate(batch_data):\n",
    "    fwd_encoder_batch[i] = model.pad_array(src, src_lim)\n",
    "    rev_encoder_batch[i] = model.pad_array(xp.flip(src, axis=0), src_lim)\n",
    "\n",
    "    tar_data = [GO_ID] + tar + [EOS_ID]\n",
    "    decoder_batch[i] = model.pad_list(tar_data, tar_lim+2, at_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fwd_encoder_batch = xp.swapaxes(fwd_encoder_batch, 0,1)\n",
    "rev_encoder_batch = xp.swapaxes(rev_encoder_batch, 0,1)\n",
    "decoder_batch = xp.swapaxes(decoder_batch, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_FWD_STATES = model.encode_speech_batch_lstm(fwd_encoder_batch, model.lstm_enc, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_REV_STATES = model.encode_speech_batch_lstm(rev_encoder_batch, model.lstm_rev_enc, train)\n",
    "# reverse the states to align them with forward encoder\n",
    "L_REV_STATES = xp.flip(L_REV_STATES, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return_shape = L_FWD_STATES.shape\n",
    "model.enc_states = F.concat((L_FWD_STATES, L_REV_STATES), axis=2)\n",
    "model.enc_states = F.swapaxes(model.enc_states, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.encode_decode_train_batch(batch_data, pad_size_speech, pad_size_en, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_FWD_STATES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_size_speech / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_size, batch_size, in_dim = fwd_encoder_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(in_size, batch_size, in_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech_feats = xp.load(os.path.join(speech_dir, \"train.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = speech_feats[\"041.001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = xp.array([[2,-2], [1,-1], [3,-3]], dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meh = F.expand_dims(haha.swapaxes(0,1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_out_size(i, p, k):\n",
    "    o = (i-k) + 2*p + 1\n",
    "    print(\"cnn out = {0:d}\".format(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_width = 2\n",
    "pad = k_width // 2\n",
    "# pad = k_width - 1\n",
    "pad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpuid >= 0:\n",
    "    # print(\"here\")\n",
    "    cuda.get_device(gpuid).use()\n",
    "c1 = L.ConvolutionND(ndim=1, in_channels=SPEECH_DIM, out_channels=1, ksize=k_width, pad=pad).to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = meh.shape[2]\n",
    "out_shape = (i-k_width) + 2*pad + 1\n",
    "print(i, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit -n1 -r2\n",
    "ha = c1(meh)\n",
    "print(ha.shape)\n",
    "print(ha.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test with small arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_test = xp.array([[2,-2,-5], [1,-1,-10], [3,-3,-9], [4,-4,-12]], dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_test, mini_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_var = F.expand_dims(mini_test.swapaxes(0,1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_k = 3; mini_pad = mini_k // 2\n",
    "minic1 = L.ConvolutionND(ndim=1, in_channels=3, out_channels=5, ksize=2, stride=1, pad=1).to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_out_size(i=4, k=2, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(minic1.W.shape)\n",
    "print(minic1.W.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one = minic1.W.data[0]\n",
    "one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_test[0], mini_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1 = one[0][0]*mini_test[0][0]\n",
    "h2 = one[1][0]*mini_test[0][1]\n",
    "h3 = one[2][0]*mini_test[0][2]\n",
    "h4 = one[0][1]*mini_test[1][0]\n",
    "h5 = one[1][1]*mini_test[1][1]\n",
    "h6 = one[2][1]*mini_test[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum([h1, h2, h3, h4, h5, h6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_cnn_out = minic1(mini_var).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_cnn_out.shape, mini_cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.max_pooling_nd(mini_cnn_out, ksize=2, stride=1, pad=mini_pad).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech_feats = {}\n",
    "speech_feats['train'] = xp.load(os.path.join(speech_dir, \"train.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_1 = speech_feats['train']['041.004']\n",
    "print(len(sp_1)), sp_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_words = [w.word for w in text_data['train']['041.004']['en']]\n",
    "en_symbols = [w.encode() for w in en_words]\n",
    "en_ids = [w2i[\"en\"].get(w, UNK_ID) for w in en_symbols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_ids_array = xp.array(en_ids, dtype=xp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.pad_sequence([en_ids_array, en_ids_array], length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_width = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp1_pad = xp.pad(sp_1, ((pad_width - len(sp_1) % pad_width,0),(0,0)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp1_pad), len(sp_1) % pad_width, len(sp1_pad) % pad_width, sp1_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_1[0,:5], sp1_pad[:20,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty_t = xp.empty(shape=(0,SPEECH_DIM), dtype=xp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_t = xp.concatenate((empty_t, sp1_pad), axis=0)\n",
    "print(empty_t.shape)\n",
    "empty_t = xp.concatenate((empty_t, sp1_pad), axis=0)\n",
    "print(empty_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp1_pad_rev = xp.flipud(sp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1_pad_rev[:3,:3], sp1_pad[-3:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_in_units 90\n",
      "using ADAM optimizer\n",
      "loading data\n",
      "finished loading data\n",
      "Starting experiment\n",
      "mfcc_kaldi_GRU_again/dev_17394sen_1-2layers_100units_rnn_word_lstm_adam_callhome_es_en_1.log\n",
      "mfcc_kaldi_GRU_again/seq2seq_17394sen_1-2layers_100units_rnn_word_lstm_adam_callhome_es_en_1.model\n",
      "num sentences=10000 and num epochs=10\n",
      "split data into 50 buckets, each of width=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2476/2476 [00:04<00:00, 575.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding labels\n",
      "11 items in bucket=1, each of length=39, max en ids=4\n",
      "98 items in bucket=2, each of length=39, max en ids=4\n",
      "188 items in bucket=3, each of length=39, max en ids=6\n",
      "145 items in bucket=4, each of length=39, max en ids=6\n",
      "148 items in bucket=5, each of length=39, max en ids=8\n",
      "124 items in bucket=6, each of length=39, max en ids=8\n",
      "105 items in bucket=7, each of length=39, max en ids=11\n",
      "102 items in bucket=8, each of length=39, max en ids=9\n",
      "102 items in bucket=9, each of length=39, max en ids=11\n",
      "82 items in bucket=10, each of length=39, max en ids=11\n",
      "94 items in bucket=11, each of length=39, max en ids=16\n",
      "82 items in bucket=12, each of length=39, max en ids=16\n",
      "69 items in bucket=13, each of length=39, max en ids=15\n",
      "68 items in bucket=14, each of length=39, max en ids=15\n",
      "73 items in bucket=15, each of length=39, max en ids=16\n",
      "70 items in bucket=16, each of length=39, max en ids=17\n",
      "52 items in bucket=17, each of length=39, max en ids=21\n",
      "55 items in bucket=18, each of length=39, max en ids=19\n",
      "54 items in bucket=19, each of length=39, max en ids=19\n",
      "46 items in bucket=20, each of length=39, max en ids=21\n",
      "42 items in bucket=21, each of length=39, max en ids=22\n",
      "52 items in bucket=22, each of length=39, max en ids=22\n",
      "36 items in bucket=23, each of length=39, max en ids=21\n",
      "36 items in bucket=24, each of length=39, max en ids=23\n",
      "27 items in bucket=25, each of length=39, max en ids=23\n",
      "42 items in bucket=26, each of length=39, max en ids=26\n",
      "34 items in bucket=27, each of length=39, max en ids=23\n",
      "22 items in bucket=28, each of length=39, max en ids=22\n",
      "21 items in bucket=29, each of length=39, max en ids=26\n",
      "24 items in bucket=30, each of length=39, max en ids=25\n",
      "24 items in bucket=31, each of length=39, max en ids=27\n",
      "22 items in bucket=32, each of length=39, max en ids=28\n",
      "20 items in bucket=33, each of length=39, max en ids=26\n",
      "15 items in bucket=34, each of length=39, max en ids=27\n",
      "12 items in bucket=35, each of length=39, max en ids=29\n",
      "18 items in bucket=36, each of length=39, max en ids=28\n",
      "16 items in bucket=37, each of length=39, max en ids=30\n",
      "13 items in bucket=38, each of length=39, max en ids=28\n",
      "16 items in bucket=39, each of length=39, max en ids=29\n",
      "11 items in bucket=40, each of length=39, max en ids=31\n",
      "13 items in bucket=41, each of length=39, max en ids=31\n",
      "11 items in bucket=42, each of length=39, max en ids=33\n",
      "10 items in bucket=43, each of length=39, max en ids=37\n",
      "10 items in bucket=44, each of length=39, max en ids=32\n",
      "7 items in bucket=45, each of length=39, max en ids=34\n",
      "8 items in bucket=46, each of length=39, max en ids=44\n",
      "8 items in bucket=47, each of length=39, max en ids=37\n",
      "12 items in bucket=48, each of length=39, max en ids=36\n",
      "9 items in bucket=49, each of length=39, max en ids=38\n",
      "117 items in bucket=50, each of length=39, max en ids=59\n"
     ]
    }
   ],
   "source": [
    "%run nmt_trials.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets_dict['train'] = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets_dict['train'][0][\"X_fwd\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buckets_dict['dev'][1][\"X_fwd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = buckets_dict['dev'][1]['X_fwd'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10, 32)\n",
      "(20, 20, 32)\n",
      "(20, 30, 32)\n",
      "(20, 40, 32)\n",
      "(20, 50, 32)\n",
      "(20, 60, 32)\n",
      "(20, 70, 32)\n",
      "(20, 80, 32)\n",
      "(20, 90, 32)\n",
      "(20, 90, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/group/project/lowres/work/anaconda3/envs/chainer2/lib/python3.6/site-packages/chainer/utils/experimental.py:104: FutureWarning: chainer.functions.pooling.MaxPoolingND is experimental. The interface can change in the future.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "out1 = model.forward_cnn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 20, 90)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "h = F.rollaxis(out1, axis=2)\n",
    "print(h.shape), \n",
    "print(model.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (8, 20, 90)\n"
     ]
    }
   ],
   "source": [
    "hf, hr = model.forward_rnn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[[             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           ..., \n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan]],\n",
       "\n",
       "          [[             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           ..., \n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan]],\n",
       "\n",
       "          [[             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           ..., \n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan]],\n",
       "\n",
       "          ..., \n",
       "          [[             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           ..., \n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan]],\n",
       "\n",
       "          [[             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           ..., \n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan],\n",
       "           [             nan,              nan,              nan, ...,\n",
       "                         nan,              nan,              nan]],\n",
       "\n",
       "          [[  2.24976331e-01,  -1.29773036e-01,  -3.01805824e-01, ...,\n",
       "              2.35336751e-01,   1.43446267e-01,   2.79089622e-02],\n",
       "           [ -1.41872335e-02,  -0.00000000e+00,  -9.93196368e-02, ...,\n",
       "              9.89654064e-02,   8.04431438e-02,   4.48617265e-02],\n",
       "           [  1.01163641e-01,   1.53301731e-02,  -0.00000000e+00, ...,\n",
       "              0.00000000e+00,   2.34413281e-01,  -1.60531960e-02],\n",
       "           ..., \n",
       "           [  0.00000000e+00,  -2.09210679e-01,  -0.00000000e+00, ...,\n",
       "              8.41930434e-02,   4.47716517e-03,  -4.26735170e-02],\n",
       "           [  5.12659103e-02,  -9.16447863e-02,  -1.50251798e-02, ...,\n",
       "              1.12554364e-01,   1.14303261e-01,  -6.40015453e-02],\n",
       "           [ -4.92044501e-02,  -1.65137038e-01,  -0.00000000e+00, ...,\n",
       "              0.00000000e+00,   1.10233650e-01,   2.64694041e-04]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "he = model.encode(h[0], model.rnn_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           ..., \n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "          [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           ..., \n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "          [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           ..., \n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "          ..., \n",
       "          [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           ..., \n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "          [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           ..., \n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "          [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           ..., \n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "           [ nan,  nan,  nan, ...,  nan,  nan,  nan]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.L0_enc = model.RNN(90,100)\n",
    "model.add_rnn_layers(['nL_0'], 90, model.n_units, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enc_dec.SpeechEncoderDecoder at 0x7f8bfdff9e80>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ 0.17088197,  0.13062714, -0.06950388, ..., -0.14050233,\n",
       "           -0.30183068, -0.19015318],\n",
       "          [-0.00132584,  0.09462968,  0.0914233 , ...,  0.00338074,\n",
       "           -0.15398282, -0.07348515],\n",
       "          [ 0.20481794,  0.09833317,  0.27618104, ...,  0.01565787,\n",
       "           -0.23376104, -0.11751523],\n",
       "          ..., \n",
       "          [ 0.14942464,  0.11332168,  0.0842166 , ...,  0.10079847,\n",
       "           -0.09364501,  0.0267418 ],\n",
       "          [ 0.06728604,  0.07206888, -0.05080219, ...,  0.03351169,\n",
       "           -0.22022687, -0.04394259],\n",
       "          [ 0.05603104,  0.09172393,  0.0522528 , ..., -0.03993868,\n",
       "           -0.26154986,  0.1199726 ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.L0_enc(h[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpuid >= 0:\n",
    "    cuda.get_device(gpuid).use()\n",
    "    lstm_test = model.RNN(90, 100)\n",
    "    lstm_test.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_rnn_layers(in_units=90, out_units=100,layer_names=['rnn_test'], scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[-0.06926221, -0.21527876, -0.04705128, ...,  0.27475366,\n",
       "           -0.37026265,  0.06866559],\n",
       "          [ 0.0130947 , -0.07874557, -0.01964537, ...,  0.02807949,\n",
       "           -0.13835178,  0.0891204 ],\n",
       "          [-0.04015987, -0.17219132,  0.05235179, ...,  0.18459854,\n",
       "            0.05624923,  0.02781546],\n",
       "          ..., \n",
       "          [-0.11278225, -0.04982725,  0.02328975, ...,  0.08394802,\n",
       "            0.12310678,  0.03418106],\n",
       "          [-0.04079617, -0.08743001, -0.1354847 , ...,  0.11196797,\n",
       "            0.19609286, -0.07657846],\n",
       "          [-0.21576719, -0.12321437,  0.06111503, ...,  0.21908043,\n",
       "           -0.26039788,  0.03160518]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_gpu()\n",
    "model.rnn_test(h[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ 0.04944006,  0.09556714, -0.44437841, ..., -0.14781998,\n",
       "            0.65636563,  0.19542442],\n",
       "          [ 0.01253496,  0.00241905, -0.49145231, ...,  0.19214736,\n",
       "            0.49585962,  0.11678124],\n",
       "          [-0.12379218,  0.00652893, -0.39462811, ..., -0.18692628,\n",
       "            0.74462467,  0.20249383],\n",
       "          ..., \n",
       "          [ 0.16764103, -0.15657805, -0.192853  , ...,  0.28847459,\n",
       "            0.29622197,  0.15147099],\n",
       "          [-0.18047023, -0.10877994,  0.0760225 , ..., -0.16628039,\n",
       "            0.40716025,  0.20774698],\n",
       "          [ 0.12239774, -0.22550839, -0.53163111, ..., -0.10556503,\n",
       "            0.29653063,  0.41799688]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_test(h[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[[ 0.48160893,  0.29182747,  0.        , ...,  0.37724853,\n",
       "             0.35354695,  1.11942744],\n",
       "           [ 0.        ,  0.        ,  0.        , ...,  0.90547466,\n",
       "             0.6689232 ,  0.55247557],\n",
       "           [ 0.07088542,  0.54246229,  0.        , ...,  0.        ,\n",
       "             0.59680718,  0.20341606],\n",
       "           ..., \n",
       "           [ 0.        ,  0.        ,  0.        , ...,  0.29700285,\n",
       "             0.63800472,  0.34882778],\n",
       "           [ 0.        ,  0.        ,  0.        , ...,  0.59988761,\n",
       "             0.62842304,  0.        ],\n",
       "           [ 0.10303846,  0.42879567,  0.67467916, ...,  1.26035666,\n",
       "             0.36838549,  0.        ]],\n",
       "\n",
       "          [[ 1.25348902,  0.02680092,  1.60453534, ...,  0.41225335,\n",
       "             1.40000391,  0.02314951],\n",
       "           [ 0.        ,  0.        ,  0.        , ...,  0.53784353,\n",
       "             0.43993512,  0.145229  ],\n",
       "           [ 2.03745151,  1.66896772,  0.        , ...,  0.33901104,\n",
       "             0.60412908,  0.        ],\n",
       "           ..., \n",
       "           [ 0.25132415,  0.13008888,  0.        , ...,  0.54930753,\n",
       "             0.3541829 ,  0.        ],\n",
       "           [ 0.5595445 ,  0.05368855,  0.        , ...,  0.92095375,\n",
       "             0.05678616,  0.11565898],\n",
       "           [ 0.08434373,  0.91121417,  0.57728988, ...,  1.42126882,\n",
       "             0.60636365,  0.13920689]],\n",
       "\n",
       "          [[ 0.        ,  2.38826942,  1.2199353 , ...,  0.47198075,\n",
       "             1.52112067,  0.        ],\n",
       "           [ 0.        ,  0.31294829,  0.        , ...,  0.18765458,\n",
       "             0.0297381 ,  0.52616763],\n",
       "           [ 1.2367878 ,  2.52685404,  0.        , ...,  0.81713581,\n",
       "             0.65471262,  0.        ],\n",
       "           ..., \n",
       "           [ 0.76514679,  0.42935961,  0.        , ...,  0.94685674,\n",
       "             0.35727611,  0.        ],\n",
       "           [ 1.31214714,  0.        ,  0.        , ...,  0.61928779,\n",
       "             0.1332027 ,  0.38151684],\n",
       "           [ 0.37309468,  0.37610549,  0.48706919, ...,  0.12496626,\n",
       "             0.37775424,  0.36949438]],\n",
       "\n",
       "          ..., \n",
       "          [[ 1.38560784,  4.15216494,  1.77406919, ...,  0.        ,\n",
       "             0.        ,  0.57901281],\n",
       "           [ 0.        ,  1.70765376,  0.25358567, ...,  0.4527618 ,\n",
       "             0.        ,  0.14443168],\n",
       "           [ 0.62156475,  3.887815  ,  1.28103614, ...,  0.09369535,\n",
       "             0.        ,  0.        ],\n",
       "           ..., \n",
       "           [ 0.74442554,  1.67020476,  0.        , ...,  0.95358467,\n",
       "             0.        ,  0.20711428],\n",
       "           [ 0.        ,  0.        ,  0.17363419, ...,  0.32350531,\n",
       "             0.22384295,  0.18837367],\n",
       "           [ 0.        ,  1.15319157,  1.87568331, ...,  0.        ,\n",
       "             0.53869957,  0.35035151]],\n",
       "\n",
       "          [[ 1.01251185,  1.55357921,  0.22693387, ...,  0.        ,\n",
       "             0.        ,  0.21823278],\n",
       "           [ 0.        ,  1.00571644,  0.        , ...,  0.        ,\n",
       "             0.        ,  0.        ],\n",
       "           [ 0.50274158,  1.45684099,  0.23690382, ...,  0.37143064,\n",
       "             0.        ,  0.        ],\n",
       "           ..., \n",
       "           [ 0.13492592,  0.62969691,  0.        , ...,  0.63330382,\n",
       "             0.        ,  0.05513028],\n",
       "           [ 0.12237476,  0.08616357,  0.39648592, ...,  0.33694199,\n",
       "             0.38331014,  0.88769603],\n",
       "           [ 0.        ,  0.89670628,  0.65119749, ...,  0.        ,\n",
       "             1.0297755 ,  0.62359935]],\n",
       "\n",
       "          [[       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                   -inf,        -inf],\n",
       "           [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                   -inf,        -inf],\n",
       "           [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                   -inf,        -inf],\n",
       "           ..., \n",
       "           [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                   -inf,        -inf],\n",
       "           [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                   -inf,        -inf],\n",
       "           [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                   -inf,        -inf]]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "          [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "          [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "          ..., \n",
       "          [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "          [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "          [ nan,  nan,  nan, ...,  nan,  nan,  nan]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.L0_rev_enc.reset_state()\n",
    "hs = model.L0_rev_enc(h[-1])\n",
    "hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.links.connection.lstm.LSTM at 0x7f8c0b051128>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[model.rnn_enc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(False, dtype=bool)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp.isnan(xp.sum(h.data)) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True, dtype=bool)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp.isnan(xp.sum(model.enc_states.data)) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward_highway(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = model.CNN_9(t)\n",
    "print(out1.shape)\n",
    "out2 = model.CNN_19(t)\n",
    "print(out2.shape)\n",
    "\n",
    "combined_out = F.concat((out1, out2), axis=1)\n",
    "print(combined_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_out_h = F.max_pooling_nd(combined_out, ksize=9, stride=10, pad=9//2)\n",
    "print(cnn_out_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_test = L.Highway()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_test(combined_out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE == MODEL_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cnn_out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_k_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_filters, model.max_pool_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.expand_dims(sp_1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(buckets[0][\"X_fwd\"].shape) * buckets[0][\"X_fwd\"].itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_data_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
