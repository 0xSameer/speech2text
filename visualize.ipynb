{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, modified_precision\n",
    "from nltk.metrics import scores\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nmt_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = [f for f in os.listdir(os.path.dirname(model_fil))\n",
    "                   if os.path.basename(model_fil).replace('.model','') in f]\n",
    "# print(model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_model_fil = max(model_files, key=lambda s: int(s.split('_')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dev_fil_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_train = np.loadtxt(log_train_fil_name, delimiter=',', skiprows=False).transpose()\n",
    "log_test = np.loadtxt(log_dev_fil_name, delimiter=',', skiprows=0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "fig.set_size_inches(8,5)\n",
    "ax1.plot(log_train[0], log_train[1], color='#ff7700')\n",
    "ax1.plot(log_test[0], log_test[1], 'r--')\n",
    "ax1.set_xlabel('epoch', size=24)\n",
    "ax1.set_ylabel('loss', color='r', size=24)\n",
    "for tl in ax1.get_yticklabels():\n",
    "    tl.set_color('r')\n",
    "    tl.set_fontsize(18)\n",
    "plt.legend(['train loss', 'dev loss'], bbox_to_anchor=(1.45, 0.96), framealpha=0, fontsize=20)    \n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(log_test[0], log_test[2]*100, 'b-')\n",
    "ax2.set_xlabel('iteration')\n",
    "ax2.set_ylabel('dev bleu', color='b', size=24)\n",
    "# ax2.set_ylim(0, 0.9)\n",
    "for tl in ax2.get_yticklabels():\n",
    "    tl.set_color('b')\n",
    "    tl.set_fontsize(18) \n",
    "plt.legend(['dev bleu'], bbox_to_anchor=(1.44, 1.04), framealpha=0, fontsize=20)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key='fisher_dev'\n",
    "train=False\n",
    "m_dict = map_dict[key]\n",
    "v_dict = vocab_dict[dec_key]\n",
    "n=len(map_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_speech_path = os.path.join(out_path, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*80)\n",
    "print(\"EPOCH = {0:d}\".format(last_epoch+1))\n",
    "pred_sents, utts, loss = feed_model(map_dict[key],\n",
    "                  b_dict=bucket_dict[key],\n",
    "                  vocab_dict=vocab_dict,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  x_key=enc_key,\n",
    "                  y_key=dec_key,\n",
    "                  train=train,\n",
    "                  cat_speech_path=cat_speech_path, use_y=True)\n",
    "\n",
    "print(\"{0:s} {1:s} mean loss={2:.4f}\".format(\"*\" * 10,\n",
    "                                    \"train\" if train else \"dev\",\n",
    "                                    loss))\n",
    "print(\"-\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_words(m_dict, v_dict, pred_sents[-50:], utts[-50:], dec_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, h, r = calc_bleu(m_dict, v_dict, pred_sents[:n], utts[:n], dec_key)\n",
    "\n",
    "print(\"BLEU score on: {0:s} = {1:.2f}\".format(key, b * 100))\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "all_weights=[(1.,0.,0.,0.),\n",
    "             (0.,1.,0.,0.),\n",
    "             (0.,0.,1.,0.),\n",
    "             (0.,0.,0.,1.),\n",
    "             (1./2,1./2,0.,0.),\n",
    "             (1./3,1./3,1./3,0.),\n",
    "             (.25,.25,.25,.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth_fun = nltk.translate.bleu_score.SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:>20s} | {1:20s}\".format(\"bleu score (0-100)\", \"uni-bi-tri-quad\"))\n",
    "for weights in all_weights:\n",
    "    b = corpus_bleu(r, h, weights=weights, smoothing_function=smooth_fun.method2)\n",
    "    print(\"{0:20.2f} | {1:20s}\".format(b * 100, \"-\".join(map(\"{0:.2f}\".format, weights))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = corpus_precision_recall(r, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callhome dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key='callhome_devtest'\n",
    "train=False\n",
    "m_dict = map_dict[key]\n",
    "v_dict = vocab_dict[dec_key]\n",
    "n=len(map_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_speech_path = os.path.join(out_path, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*80)\n",
    "print(\"EPOCH = {0:d}\".format(last_epoch+1))\n",
    "pred_sents, utts, loss = feed_model(map_dict[key],\n",
    "                  b_dict=bucket_dict[key],\n",
    "                  vocab_dict=vocab_dict,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  x_key=enc_key,\n",
    "                  y_key=dec_key,\n",
    "                  train=train,\n",
    "                  cat_speech_path=cat_speech_path, use_y=True)\n",
    "\n",
    "print(\"{0:s} {1:s} mean loss={2:.4f}\".format(\"*\" * 10,\n",
    "                                    \"train\" if train else \"dev\",\n",
    "                                    loss))\n",
    "print(\"-\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_words(m_dict, v_dict, pred_sents[-50:], utts[-50:], dec_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, h, r = calc_bleu(m_dict, v_dict, pred_sents[:n], utts[:n], dec_key)\n",
    "\n",
    "print(\"BLEU score on: {0:s} = {1:.2f}\".format(key, b * 100))\n",
    "\n",
    "print(\"-\"*60)\n",
    "\n",
    "all_weights=[(1.,0.,0.,0.),\n",
    "             (0.,1.,0.,0.),\n",
    "             (0.,0.,1.,0.),\n",
    "             (0.,0.,0.,1.),\n",
    "             (1./2,1./2,0.,0.),\n",
    "             (1./3,1./3,1./3,0.),\n",
    "             (.25,.25,.25,.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth_fun = nltk.translate.bleu_score.SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:>20s} | {1:20s}\".format(\"bleu score (0-100)\", \"uni-bi-tri-quad\"))\n",
    "for weights in all_weights:\n",
    "    b = corpus_bleu(r, h, weights=weights, smoothing_function=smooth_fun.method2)\n",
    "    print(\"{0:20.2f} | {1:20s}\".format(b * 100, \"-\".join(map(\"{0:.2f}\".format, weights))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = corpus_precision_recall(r, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_ref = [[\"ha ha lol hue\".split()], [\"ha ha ja ha\".split()], [\"ha ha ja ha\".split()]]\n",
    "# test_h = [\"lol ja\".split(), \"ha he\".split(), \"ha ja\".split()]\n",
    "# _, _ = corpus_precision_recall(test_ref, test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
